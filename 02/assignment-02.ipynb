{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ee4e580d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2026-01-04 17:11:19--  https://www.gutenberg.org/cache/epub/34225/pg34225.txt\n",
      "Resolving www.gutenberg.org (www.gutenberg.org)... 152.19.134.47, 2610:28:3090:3000:0:bad:cafe:47\n",
      "Connecting to www.gutenberg.org (www.gutenberg.org)|152.19.134.47|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 769766 (752K) [text/plain]\n",
      "Saving to: ‘guthenberg-cs.txt’\n",
      "\n",
      "guthenberg-cs.txt   100%[===================>] 751,72K  1,28MB/s    in 0,6s    \n",
      "\n",
      "2026-01-04 17:11:20 (1,28 MB/s) - ‘guthenberg-cs.txt’ saved [769766/769766]\n",
      "\n",
      "--2026-01-04 17:11:20--  https://www.gutenberg.org/cache/epub/37536/pg37536.txt\n",
      "Resolving www.gutenberg.org (www.gutenberg.org)... 152.19.134.47, 2610:28:3090:3000:0:bad:cafe:47\n",
      "Connecting to www.gutenberg.org (www.gutenberg.org)|152.19.134.47|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 724943 (708K) [text/plain]\n",
      "Saving to: ‘guthenberg-en.txt’\n",
      "\n",
      "guthenberg-en.txt   100%[===================>] 707,95K  1,16MB/s    in 0,6s    \n",
      "\n",
      "2026-01-04 17:11:21 (1,16 MB/s) - ‘guthenberg-en.txt’ saved [724943/724943]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget -O \"guthenberg-cs.txt\" \"https://www.gutenberg.org/cache/epub/34225/pg34225.txt\"\n",
    "!wget -O \"guthenberg-en.txt\" \"https://www.gutenberg.org/cache/epub/37536/pg37536.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "39ca6185",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: sacremoses in /mnt/disk/patrik/nlp/.venv_nlp/lib/python3.10/site-packages (0.1.1)\n",
      "Requirement already satisfied: tqdm in /mnt/disk/patrik/nlp/.venv_nlp/lib/python3.10/site-packages (from sacremoses) (4.67.1)\n",
      "Requirement already satisfied: click in /mnt/disk/patrik/nlp/.venv_nlp/lib/python3.10/site-packages (from sacremoses) (8.3.1)\n",
      "Requirement already satisfied: regex in /mnt/disk/patrik/nlp/.venv_nlp/lib/python3.10/site-packages (from sacremoses) (2025.11.3)\n",
      "Requirement already satisfied: joblib in /mnt/disk/patrik/nlp/.venv_nlp/lib/python3.10/site-packages (from sacremoses) (1.5.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install sacremoses\n",
    "\n",
    "from sacremoses import MosesTokenizer, MosesDetokenizer\n",
    "import os\n",
    "from collections import Counter, defaultdict\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "64997666",
   "metadata": {},
   "outputs": [],
   "source": [
    "filenames = {\"cs\": \"guthenberg-cs.txt\",\"en\": \"guthenberg-en.txt\"}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "de54e735",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cs: 769766 bytes\n",
      "en: 724943 bytes\n"
     ]
    }
   ],
   "source": [
    "for name in filenames:\n",
    "    print(f\"{name}: {os.path.getsize(filenames[name])} bytes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c9186162",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_full = {}\n",
    "\n",
    "for lang in filenames:\n",
    "    with open(filenames[lang], \"r\") as f:\n",
    "        corpus_full[lang] = f.read()\n",
    "\n",
    "data = {lang: MosesTokenizer(lang).tokenize(corpus_full[lang]) for lang in corpus_full}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "88f0245f",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_special_symbol, end_special_symbol = \"<s>\", \"</s>\"\n",
    "\n",
    "get_unigrams = lambda tokens : Counter(tokens + [start_special_symbol, end_special_symbol])\n",
    "get_bigrams = lambda tokens : Counter(zip([start_special_symbol] + tokens, tokens + [end_special_symbol]))\n",
    "get_trigrams = lambda tokens : Counter(zip(2 * [start_special_symbol] + tokens, [start_special_symbol] + tokens + [end_special_symbol], tokens + 2 * [end_special_symbol]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "efabf894",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of english tokenized data: 149191\n",
      "Length of czech tokenized data: 136966\n",
      "Unique tokens in english 30k dataset: 4426\n",
      "Unique tokens in czech 15k dataset: 4950\n"
     ]
    }
   ],
   "source": [
    "print(\"Length of english tokenized data:\", len(data[\"en\"]))\n",
    "data[\"en\"] = data[\"en\"][:30_000]\n",
    "print(\"Length of czech tokenized data:\", len(data[\"cs\"]))\n",
    "data[\"cs\"] = data[\"cs\"][:15_000]\n",
    "print(\"Unique tokens in english 30k dataset:\", len(set(data[\"en\"])))\n",
    "print(\"Unique tokens in czech 15k dataset:\", len(set(data[\"cs\"])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b130e5a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "English tokens with at least 50 occurrences: 73\n",
      "Czech tokens with at least 20 occurrences: 77\n"
     ]
    }
   ],
   "source": [
    "uni = {lang: get_unigrams(data[lang]) for lang in data}\n",
    "bi = {lang: get_bigrams(data[lang]) for lang in data}\n",
    "\n",
    "print(\"English tokens with at least 50 occurrences:\", len([token for token, count in uni[\"en\"].items() if count >= 50]))\n",
    "print(\"Czech tokens with at least 20 occurrences:\", len([token for token, count in uni[\"cs\"].items() if count >= 20]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e3955a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial mutual information is : 1.4853262751992053\n",
      "Class 6 words: ['and']\n",
      "Class 13 words: ['or']\n",
      "Class 6 check: ['and']\n",
      "Class 13 check: ['or']\n",
      "Number of classes 72, loss=-0.103137, remaining=72\n",
      "Class 1 words: ['of']\n",
      "Class 5 words: ['in']\n",
      "Class 1 check: ['of']\n",
      "Class 5 check: ['in']\n",
      "Number of classes 71, loss=-0.044501, remaining=71\n",
      "Class 8 words: ['it']\n",
      "Class 30 words: ['he']\n",
      "Class 8 check: ['it']\n",
      "Class 30 check: ['he']\n",
      "Number of classes 70, loss=-0.052599, remaining=70\n",
      "Class 3 words: ['for']\n",
      "Class 6 words: ['with']\n",
      "Class 3 check: ['for']\n",
      "Class 6 check: ['with']\n",
      "Number of classes 69, loss=-0.017065, remaining=69\n",
      "Class 2 words: ['is']\n",
      "Class 66 words: ['it', 'he']\n",
      "Class 2 check: ['is']\n",
      "Class 66 check: ['it', 'he']\n",
      "Number of classes 68, loss=-0.031190, remaining=68\n",
      "Class 60 words: ['convict']\n",
      "Class 61 words: ['prison']\n",
      "Class 60 check: ['convict']\n",
      "Class 61 check: ['prison']\n",
      "Number of classes 67, loss=-0.005815, remaining=67\n",
      "Class 8 words: ['are']\n",
      "Class 35 words: ['would']\n",
      "Class 8 check: ['are']\n",
      "Class 35 check: ['would']\n",
      "Number of classes 66, loss=-0.007852, remaining=66\n",
      "Class 2 words: ['at']\n",
      "Class 29 words: ['on']\n",
      "Class 2 check: ['at']\n",
      "Class 29 check: ['on']\n",
      "Number of classes 65, loss=-0.009827, remaining=65\n",
      "Class 24 words: ['as']\n",
      "Class 40 words: ['my']\n",
      "Class 24 check: ['as']\n",
      "Class 40 check: ['my']\n",
      "Number of classes 64, loss=-0.003497, remaining=64\n",
      "Class 8 words: ['will']\n",
      "Class 33 words: ['has']\n",
      "Class 8 check: ['will']\n",
      "Class 33 check: ['has']\n",
      "Number of classes 63, loss=-0.003617, remaining=63\n",
      "Class 59 words: ['at', 'on']\n",
      "Class 60 words: ['as', 'my']\n",
      "Class 59 check: ['at', 'on']\n",
      "Class 60 check: ['as', 'my']\n",
      "Number of classes 62, loss=-0.025651, remaining=62\n",
      "Class 14 words: [';']\n",
      "Class 38 words: ['but']\n",
      "Class 14 check: [';']\n",
      "Class 38 check: ['but']\n",
      "Number of classes 61, loss=-0.002216, remaining=61\n",
      "Class 22 words: ['an']\n",
      "Class 57 words: ['will', 'has']\n",
      "Class 22 check: ['an']\n",
      "Class 57 check: ['will', 'has']\n",
      "Number of classes 60, loss=-0.002268, remaining=60\n",
      "Class 2 words: ['no']\n",
      "Class 15 words: ['a']\n",
      "Class 2 check: ['no']\n",
      "Class 15 check: ['a']\n",
      "Number of classes 59, loss=-0.004020, remaining=59\n",
      "Class 14 words: ['that']\n",
      "Class 40 words: ['there']\n",
      "Class 14 check: ['that']\n",
      "Class 40 check: ['there']\n",
      "Number of classes 58, loss=0.000827, remaining=58\n",
      "Class 25 words: ['very']\n",
      "Class 55 words: ['no', 'a']\n",
      "Class 25 check: ['very']\n",
      "Class 55 check: ['no', 'a']\n",
      "Number of classes 57, loss=-0.051085, remaining=57\n",
      "Class 51 words: ['at', 'as', 'on', 'my']\n",
      "Class 52 words: [';', 'but']\n",
      "Class 51 check: ['at', 'as', 'on', 'my']\n",
      "Class 52 check: [';', 'but']\n",
      "Number of classes 56, loss=-0.030956, remaining=56\n",
      "Class 40 words: ['man']\n",
      "Class 43 words: ['day']\n",
      "Class 40 check: ['man']\n",
      "Class 43 check: ['day']\n",
      "Number of classes 55, loss=-0.000358, remaining=55\n",
      "Class 12 words: ['’']\n",
      "Class 51 words: ['no', 'a', 'very']\n",
      "Class 12 check: ['’']\n",
      "Class 51 check: ['no', 'a', 'very']\n",
      "Number of classes 54, loss=-0.001044, remaining=54\n",
      "Class 28 words: ['him']\n",
      "Class 38 words: ['me']\n",
      "Class 28 check: ['him']\n",
      "Class 38 check: ['me']\n",
      "Number of classes 53, loss=0.000394, remaining=53\n",
      "Class 12 words: ['“']\n",
      "Class 15 words: ['”']\n",
      "Class 12 check: ['“']\n",
      "Class 15 check: ['”']\n",
      "Number of classes 52, loss=0.001061, remaining=52\n",
      "Class 30 words: ['up']\n",
      "Class 42 words: ['convict', 'prison']\n",
      "Class 30 check: ['up']\n",
      "Class 42 check: ['convict', 'prison']\n",
      "Number of classes 51, loss=0.001206, remaining=51\n",
      "Class 4 words: ['this']\n",
      "Class 38 words: ['of', 'in']\n",
      "Class 4 check: ['this']\n",
      "Class 38 check: ['of', 'in']\n",
      "Number of classes 50, loss=-0.001002, remaining=50\n",
      "Class 8 words: ['was']\n",
      "Class 27 words: ['could']\n",
      "Class 8 check: ['was']\n",
      "Class 27 check: ['could']\n",
      "Number of classes 49, loss=0.002212, remaining=49\n",
      "Class 1 words: ['the']\n",
      "Class 16 words: ['so']\n",
      "Class 1 check: ['the']\n",
      "Class 16 check: ['so']\n",
      "Number of classes 48, loss=0.000755, remaining=48\n",
      "Class 15 words: ['be']\n",
      "Class 26 words: ['time']\n",
      "Class 15 check: ['be']\n",
      "Class 26 check: ['time']\n",
      "Number of classes 47, loss=0.001546, remaining=47\n",
      "Class 8 words: ['by']\n",
      "Class 30 words: ['and', 'or', 'prisoners']\n",
      "Class 8 check: ['by']\n",
      "Class 30 check: ['and', 'or', 'prisoners']\n",
      "Number of classes 46, loss=0.000106, remaining=46\n",
      "Class 15 words: ['It']\n",
      "Class 25 words: ['They']\n",
      "Class 15 check: ['It']\n",
      "Class 25 check: ['They']\n",
      "Number of classes 45, loss=0.004550, remaining=45\n",
      "Class 25 words: ['all']\n",
      "Class 43 words: ['It', 'They']\n",
      "Class 25 check: ['all']\n",
      "Class 43 check: ['It', 'They']\n",
      "Number of classes 44, loss=0.004043, remaining=44\n",
      "Class 10 words: ['his']\n",
      "Class 24 words: ['some']\n",
      "Class 10 check: ['his']\n",
      "Class 24 check: ['some']\n",
      "Number of classes 43, loss=0.002123, remaining=43\n",
      "Class 11 words: ['who']\n",
      "Class 15 words: ['which']\n",
      "Class 11 check: ['who']\n",
      "Class 15 check: ['which']\n",
      "Number of classes 42, loss=0.005159, remaining=42\n",
      "Class 31 words: ['“', '”']\n",
      "Class 37 words: ['and', 'or', 'by', 'prisoners']\n",
      "Class 31 check: ['“', '”']\n",
      "Class 37 check: ['and', 'or', 'by', 'prisoners']\n",
      "Number of classes 41, loss=0.010193, remaining=41\n",
      "Class 14 words: ['one']\n",
      "Class 21 words: ['convicts']\n",
      "Class 14 check: ['one']\n",
      "Class 21 check: ['convicts']\n",
      "Number of classes 40, loss=0.010386, remaining=40\n",
      "Class 16 words: ['been']\n",
      "Class 17 words: ['?']\n",
      "Class 16 check: ['been']\n",
      "Class 17 check: ['?']\n",
      "Number of classes 39, loss=0.012806, remaining=39\n",
      "Class 4 words: ['not']\n",
      "Class 6 words: ['to']\n",
      "Class 4 check: ['not']\n",
      "Class 6 check: ['to']\n",
      "Number of classes 38, loss=0.012373, remaining=38\n",
      "Class 4 words: ['have']\n",
      "Class 35 words: ['been', '?']\n",
      "Class 4 check: ['have']\n",
      "Class 35 check: ['been', '?']\n",
      "Number of classes 37, loss=0.011196, remaining=37\n",
      "Class 30 words: ['his', 'some']\n",
      "Class 32 words: ['and', 'or', 'by', '“', '”', 'prisoners']\n",
      "Class 30 check: ['his', 'some']\n",
      "Class 32 check: ['and', 'or', 'by', '“', '”', 'prisoners']\n",
      "Number of classes 36, loss=0.013049, remaining=36\n",
      "Class 10 words: ['himself']\n",
      "Class 14 words: ['little']\n",
      "Class 10 check: ['himself']\n",
      "Class 14 check: ['little']\n",
      "Number of classes 35, loss=0.013929, remaining=35\n",
      "Class 15 words: ['are', 'would']\n",
      "Class 23 words: ['of', 'in', 'this']\n",
      "Class 15 check: ['are', 'would']\n",
      "Class 23 check: ['of', 'in', 'this']\n",
      "Number of classes 34, loss=0.018698, remaining=34\n",
      "Class 6 words: ['them']\n",
      "Class 27 words: ['one', 'convicts']\n",
      "Class 6 check: ['them']\n",
      "Class 27 check: ['one', 'convicts']\n",
      "Number of classes 33, loss=0.007494, remaining=33\n",
      "Class 6 words: ['He']\n",
      "Class 11 words: ['I']\n",
      "Class 6 check: ['He']\n",
      "Class 11 check: ['I']\n",
      "Number of classes 32, loss=0.018273, remaining=32\n",
      "Class 8 words: ['had']\n",
      "Class 20 words: ['the', 'so']\n",
      "Class 8 check: ['had']\n",
      "Class 20 check: ['the', 'so']\n",
      "Number of classes 31, loss=0.016169, remaining=31\n",
      "Class 6 words: ['were']\n",
      "Class 10 words: ['is', 'it', 'he']\n",
      "Class 6 check: ['were']\n",
      "Class 10 check: ['is', 'it', 'he']\n",
      "Number of classes 30, loss=0.015805, remaining=30\n",
      "Class 3 words: ['you']\n",
      "Class 16 words: ['was', 'could']\n",
      "Class 3 check: ['you']\n",
      "Class 16 check: ['was', 'could']\n",
      "Number of classes 29, loss=-0.001194, remaining=29\n",
      "Class 5 words: ['they']\n",
      "Class 22 words: ['of', 'in', 'this', 'are', 'would']\n",
      "Class 5 check: ['they']\n",
      "Class 22 check: ['of', 'in', 'this', 'are', 'would']\n",
      "Number of classes 28, loss=0.009890, remaining=28\n",
      "Class 21 words: ['them', 'one', 'convicts']\n",
      "Class 22 words: ['He', 'I']\n",
      "Class 21 check: ['them', 'one', 'convicts']\n",
      "Class 22 check: ['He', 'I']\n",
      "Number of classes 27, loss=0.028914, remaining=27\n",
      "Class 20 words: ['himself', 'little']\n",
      "Class 25 words: ['them', 'He', 'one', 'I', 'convicts']\n",
      "Class 20 check: ['himself', 'little']\n",
      "Class 25 check: ['them', 'He', 'one', 'I', 'convicts']\n",
      "Number of classes 26, loss=0.014913, remaining=26\n",
      "Class 0 words: ['The']\n",
      "Class 13 words: ['up', 'convict', 'prison']\n",
      "Class 0 check: ['The']\n",
      "Class 13 check: ['up', 'convict', 'prison']\n",
      "Number of classes 25, loss=0.022068, remaining=25\n",
      "Class 8 words: ['at', ';', 'as', 'on', 'my', 'but']\n",
      "Class 14 words: ['who', 'which']\n",
      "Class 8 check: ['at', ';', 'as', 'on', 'my', 'but']\n",
      "Class 14 check: ['who', 'which']\n",
      "Number of classes 24, loss=0.024684, remaining=24\n",
      "Class 15 words: ['and', 'or', 'by', '“', '”', 'his', 'some', 'prisoners']\n",
      "Class 21 words: ['The', 'up', 'convict', 'prison']\n",
      "Class 15 check: ['and', 'or', 'by', '“', '”', 'his', 'some', 'prisoners']\n",
      "Class 21 check: ['The', 'up', 'convict', 'prison']\n",
      "Number of classes 23, loss=0.031914, remaining=23\n",
      "Class 5 words: ['for', 'with']\n",
      "Class 17 words: ['you', 'was', 'could']\n",
      "Class 5 check: ['for', 'with']\n",
      "Class 17 check: ['you', 'was', 'could']\n",
      "Number of classes 22, loss=0.036119, remaining=22\n",
      "Class 3 words: ['their']\n",
      "Class 10 words: ['be', 'time']\n",
      "Class 3 check: ['their']\n",
      "Class 10 check: ['be', 'time']\n",
      "Number of classes 21, loss=0.015095, remaining=21\n",
      "Class 3 words: ['when']\n",
      "Class 18 words: ['for', 'with', 'you', 'was', 'could']\n",
      "Class 3 check: ['when']\n",
      "Class 18 check: ['for', 'with', 'you', 'was', 'could']\n",
      "Number of classes 20, loss=0.040025, remaining=20\n",
      "Class 15 words: ['at', ';', 'as', 'who', 'on', 'which', 'my', 'but']\n",
      "Class 19 words: []\n",
      "Class 15 check: ['at', ';', 'as', 'who', 'on', 'which', 'my', 'but']\n",
      "Class 19 check: []\n",
      "Number of classes 19, loss=0.025003, remaining=19\n",
      "Class 10 words: ['have', 'been', '?']\n",
      "Class 16 words: ['their', 'be', 'time']\n",
      "Class 10 check: ['have', 'been', '?']\n",
      "Class 16 check: ['their', 'be', 'time']\n",
      "Number of classes 18, loss=0.016304, remaining=18\n",
      "Class 1 words: [',']\n",
      "Class 9 words: ['not', 'to']\n",
      "Class 1 check: [',']\n",
      "Class 9 check: ['not', 'to']\n",
      "Number of classes 17, loss=0.055886, remaining=17\n",
      "Class 13 words: ['for', 'at', 'with', 'you', 'was', ';', 'as', 'who', 'on', 'which', 'when', 'my', 'but', 'could']\n",
      "Class 14 words: ['have', 'their', 'be', 'been', '?', 'time']\n",
      "Class 13 check: ['for', 'at', 'with', 'you', 'was', ';', 'as', 'who', 'on', 'which', 'when', 'my', 'but', 'could']\n",
      "Class 14 check: ['have', 'their', 'be', 'been', '?', 'time']\n",
      "Number of classes 16, loss=0.016003, remaining=16\n",
      "Class 11 words: ['them', 'He', 'himself', 'one', 'I', 'little', 'convicts']\n",
      "Class 13 words: [',', 'not', 'to']\n",
      "Class 11 check: ['them', 'He', 'himself', 'one', 'I', 'little', 'convicts']\n",
      "Class 13 check: [',', 'not', 'to']\n",
      "Number of classes 15, loss=0.035456, remaining=15\n"
     ]
    }
   ],
   "source": [
    "# THIS ONE SHOULD WORK PROBABLY\n",
    "\n",
    "def get_class_bigrams(word2class, bigrams):\n",
    "    class_bigrams = defaultdict(int)\n",
    "    for (w1, w2), count in bigrams.items():\n",
    "        c1, c2 = word2class[w1], word2class[w2]\n",
    "        class_bigrams[(c1, c2)] += count\n",
    "    return class_bigrams\n",
    "\n",
    "def get_class_bigrams_matrix(word2class, bigrams):\n",
    "    class_bigrams_matrix = np.zeros((len(word2class), len(word2class)), dtype=int)\n",
    "    for (l, r), count in bigrams.items():\n",
    "        if l not in word2class or r not in word2class:\n",
    "            continue\n",
    "        c1, c2 = word2class[l], word2class[r]\n",
    "        class_bigrams_matrix[c1, c2] += count\n",
    "    return class_bigrams_matrix\n",
    "\n",
    "def q(classes_matrix,l,r,N): # q_k(l,r)\n",
    "    c_k = classes_matrix[l,r]\n",
    "    c_kl = classes_matrix[l,:].sum()\n",
    "    c_kr = classes_matrix[:,r].sum()\n",
    "    if c_kl == 0 or c_kr == 0 or c_k == 0:\n",
    "        return 0.0\n",
    "    return c_k / N * np.log(N * c_k / (c_kl * c_kr))\n",
    "\n",
    "def test_merge(m, a, b):\n",
    "    \"\"\"\n",
    "    m : matrix[i,j] = # bigrams class i -> class j\n",
    "    a, b : classes to merge\n",
    "    should return mutal information of something\n",
    "    \"\"\"\n",
    "    if a > b:\n",
    "        a, b = b, a\n",
    "\n",
    "    # new merged row / column\n",
    "    new_row = m[a, :] + m[b, :]\n",
    "    new_col = m[:, a] + m[:, b]\n",
    "\n",
    "    # remove a and b\n",
    "    m2 = np.delete(m, [a, b], axis=0)\n",
    "    m2 = np.delete(m2, [a, b], axis=1)\n",
    "\n",
    "    # append merged row and column\n",
    "    m2 = np.vstack([m2, new_row[np.newaxis, :-2]])\n",
    "    new_col = np.append(new_col[:-2], new_row[-2])\n",
    "    m2 = np.column_stack([m2, new_col])\n",
    "\n",
    "    return m2\n",
    "\n",
    "\n",
    "def apply_merge_word2class(word2class, a, b, K):\n",
    "    \"\"\"\n",
    "    Update word2class after merging classes a and b.\n",
    "    K = number of classes BEFORE merge\n",
    "    \"\"\"\n",
    "    if a > b:\n",
    "        a, b = b, a\n",
    "\n",
    "    classA = []\n",
    "    classB = []\n",
    "    classAcheck = []\n",
    "    classBcheck = []\n",
    "\n",
    "    for w,c in word2class.items():\n",
    "        if c == a:\n",
    "            classAcheck.append(w)\n",
    "        if c == b:\n",
    "            classBcheck.append(w)\n",
    "\n",
    "    new_class = K - 2  # index of merged class\n",
    "\n",
    "    new_word2class = {}\n",
    "    for w, c in word2class.items():\n",
    "        if c == a:\n",
    "            new_word2class[w] = new_class\n",
    "            classA.append(w)\n",
    "        elif c == b:\n",
    "            new_word2class[w] = new_class\n",
    "            classB.append(w)\n",
    "        elif c < a:\n",
    "            new_word2class[w] = c\n",
    "        elif a < c < b:\n",
    "            new_word2class[w] = c - 1\n",
    "        else:  # c > b\n",
    "            new_word2class[w] = c - 2\n",
    "\n",
    "    print(f\"Class {a} words: {classA}\")\n",
    "    print(f\"Class {b} words: {classB}\")\n",
    "\n",
    "    print(f\"Class {a} check: {classAcheck}\")\n",
    "    print(f\"Class {b} check: {classBcheck}\")\n",
    "\n",
    "    return new_word2class\n",
    "\n",
    "\n",
    "def mutual_information(classes_matrix, N):\n",
    "    mi = 0\n",
    "    for i in range(classes_matrix.shape[0]):\n",
    "        for j in range(classes_matrix.shape[1]):\n",
    "            mi += q(classes_matrix, i, j, N)\n",
    "    return mi\n",
    "\n",
    "\n",
    "def word_classes(initial_words, unigrams, bigrams, target_number=15):\n",
    "    N = sum(unigrams.values()) # total number of tokens\n",
    "    word2class = {w:i for i, (w,count) in enumerate(initial_words.items())} # r function word2class[word] = class_id\n",
    "    class_bigrams_matrix = get_class_bigrams_matrix(word2class, bigrams) # i,j position -> #bigrams s.t. class i-> class j\n",
    "\n",
    "    # N = np.sum(class_bigrams_matrix)\n",
    "    \n",
    "    mi = mutual_information(class_bigrams_matrix, N)\n",
    "\n",
    "    print(f\"Initial mutual information is : {mi}\")\n",
    "\n",
    "    while class_bigrams_matrix.shape[0] > target_number:\n",
    "        # print(f\"Current number of classes: {class_bigrams_matrix.shape[0]}, MI={mi:.6f}\")\n",
    "\n",
    "        best_loss = float(\"inf\")\n",
    "        best_pair = None\n",
    "        best_matrix = None\n",
    "\n",
    "        K = class_bigrams_matrix.shape[0]\n",
    "\n",
    "        for a in range(K):\n",
    "            for b in range(a + 1, K):\n",
    "                # test merge\n",
    "                merged_matrix = test_merge(class_bigrams_matrix, a, b)\n",
    "                merged_mi = mutual_information(merged_matrix, N)\n",
    "                loss = mi - merged_mi\n",
    "\n",
    "                if loss < best_loss:\n",
    "                    best_loss = loss\n",
    "                    best_pair = (a, b)\n",
    "                    best_matrix = merged_matrix\n",
    "\n",
    "        # apply best merge\n",
    "        a, b = best_pair\n",
    "        class_bigrams_matrix = best_matrix\n",
    "        word2class = apply_merge_word2class(word2class, a, b, class_bigrams_matrix.shape[0])\n",
    "        mi -= best_loss\n",
    "\n",
    "        print(\n",
    "            f\"Number of classes {class_bigrams_matrix.shape[0]}, loss={best_loss:.6f}\"\n",
    "        )\n",
    "\n",
    "\n",
    "    return class_bigrams_matrix, word2class\n",
    "\n",
    "\n",
    "\n",
    "m, w2c = word_classes({w:c for w,c in get_unigrams(data[\"en\"]).items() if c >= 50}, get_unigrams(data[\"en\"]), get_bigrams(data[\"en\"]), target_number=15)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "38cc9b0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = [[] for _ in range(14)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "175fa79f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for w,c in w2c.items():\n",
    "    a[c].append(w)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "0a36634a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['.'],\n",
       " ['from'],\n",
       " ['will', 'an', 'has'],\n",
       " ['that', 'there'],\n",
       " ['man', 'day'],\n",
       " ['no', '’', 'a', 'very'],\n",
       " ['him', 'me'],\n",
       " ['It', 'They', 'all'],\n",
       " ['the', 'so', 'had'],\n",
       " ['is', 'it', 'he', 'were'],\n",
       " ['of', 'in', 'this', 'are', 'they', 'would'],\n",
       " ['The',\n",
       "  'and',\n",
       "  'or',\n",
       "  'by',\n",
       "  '“',\n",
       "  '”',\n",
       "  'his',\n",
       "  'up',\n",
       "  'some',\n",
       "  'convict',\n",
       "  'prison',\n",
       "  'prisoners'],\n",
       " ['for',\n",
       "  'at',\n",
       "  'with',\n",
       "  'you',\n",
       "  'have',\n",
       "  'was',\n",
       "  ';',\n",
       "  'their',\n",
       "  'as',\n",
       "  'who',\n",
       "  'on',\n",
       "  'be',\n",
       "  'which',\n",
       "  'when',\n",
       "  'my',\n",
       "  'been',\n",
       "  'but',\n",
       "  'could',\n",
       "  '?',\n",
       "  'time'],\n",
       " [',', 'not', 'to', 'them', 'He', 'himself', 'one', 'I', 'little', 'convicts']]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5f932b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# [a for a,b in w2c.items() if b == 181]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dcdc05a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.where(m == 144)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90342bbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !wget \"https://ufallab.ms.mff.cuni.cz/~helcl/npfl147/cc.en.50.bin\"\n",
    "# !wget \"https://ufallab.ms.mff.cuni.cz/~helcl/npfl147/cc.cs.50.bin\"\n",
    "# import fasttext\n",
    "# ft_en = fasttext.load_model('cc.en.50.bin')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv_nlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
