{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ee4e580d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2026-01-03 14:48:32--  https://www.gutenberg.org/cache/epub/34225/pg34225.txt\n",
      "Resolving www.gutenberg.org (www.gutenberg.org)... 152.19.134.47, 2610:28:3090:3000:0:bad:cafe:47\n",
      "Connecting to www.gutenberg.org (www.gutenberg.org)|152.19.134.47|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 769766 (752K) [text/plain]\n",
      "Saving to: ‘guthenberg-cs.txt’\n",
      "\n",
      "guthenberg-cs.txt   100%[===================>] 751,72K  1,18MB/s    in 0,6s    \n",
      "\n",
      "2026-01-03 14:48:33 (1,18 MB/s) - ‘guthenberg-cs.txt’ saved [769766/769766]\n",
      "\n",
      "--2026-01-03 14:48:34--  https://www.gutenberg.org/cache/epub/37536/pg37536.txt\n",
      "Resolving www.gutenberg.org (www.gutenberg.org)... 152.19.134.47, 2610:28:3090:3000:0:bad:cafe:47\n",
      "Connecting to www.gutenberg.org (www.gutenberg.org)|152.19.134.47|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 724943 (708K) [text/plain]\n",
      "Saving to: ‘guthenberg-en.txt’\n",
      "\n",
      "guthenberg-en.txt   100%[===================>] 707,95K  1,12MB/s    in 0,6s    \n",
      "\n",
      "2026-01-03 14:48:35 (1,12 MB/s) - ‘guthenberg-en.txt’ saved [724943/724943]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget -O \"guthenberg-cs.txt\" \"https://www.gutenberg.org/cache/epub/34225/pg34225.txt\"\n",
    "!wget -O \"guthenberg-en.txt\" \"https://www.gutenberg.org/cache/epub/37536/pg37536.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "39ca6185",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: sacremoses in /mnt/disk/patrik/nlp/.venv_nlp/lib/python3.10/site-packages (0.1.1)\n",
      "Requirement already satisfied: regex in /mnt/disk/patrik/nlp/.venv_nlp/lib/python3.10/site-packages (from sacremoses) (2025.11.3)\n",
      "Requirement already satisfied: tqdm in /mnt/disk/patrik/nlp/.venv_nlp/lib/python3.10/site-packages (from sacremoses) (4.67.1)\n",
      "Requirement already satisfied: click in /mnt/disk/patrik/nlp/.venv_nlp/lib/python3.10/site-packages (from sacremoses) (8.3.1)\n",
      "Requirement already satisfied: joblib in /mnt/disk/patrik/nlp/.venv_nlp/lib/python3.10/site-packages (from sacremoses) (1.5.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install sacremoses\n",
    "\n",
    "from sacremoses import MosesTokenizer, MosesDetokenizer\n",
    "import os\n",
    "from collections import Counter, defaultdict\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "64997666",
   "metadata": {},
   "outputs": [],
   "source": [
    "filenames = {\"cs\": \"guthenberg-cs.txt\",\"en\": \"guthenberg-en.txt\"}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "de54e735",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cs: 769766 bytes\n",
      "en: 724943 bytes\n"
     ]
    }
   ],
   "source": [
    "for name in filenames:\n",
    "    print(f\"{name}: {os.path.getsize(filenames[name])} bytes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c9186162",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_full = {}\n",
    "\n",
    "for lang in filenames:\n",
    "    with open(filenames[lang], \"r\") as f:\n",
    "        corpus_full[lang] = f.read()\n",
    "\n",
    "data = {lang: MosesTokenizer(lang).tokenize(corpus_full[lang]) for lang in corpus_full}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "88f0245f",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_special_symbol, end_special_symbol = \"<s>\", \"</s>\"\n",
    "\n",
    "get_unigrams = lambda tokens : Counter(tokens + [start_special_symbol, end_special_symbol])\n",
    "get_bigrams = lambda tokens : Counter(zip([start_special_symbol] + tokens, tokens + [end_special_symbol]))\n",
    "get_trigrams = lambda tokens : Counter(zip(2 * [start_special_symbol] + tokens, [start_special_symbol] + tokens + [end_special_symbol], tokens + 2 * [end_special_symbol]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "efabf894",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of english tokenized data: 149191\n",
      "Length of czech tokenized data: 136966\n",
      "Unique tokens in english 30k dataset: 4426\n",
      "Unique tokens in czech 15k dataset: 4950\n"
     ]
    }
   ],
   "source": [
    "print(\"Length of english tokenized data:\", len(data[\"en\"]))\n",
    "data[\"en\"] = data[\"en\"][:30_000]\n",
    "print(\"Length of czech tokenized data:\", len(data[\"cs\"]))\n",
    "data[\"cs\"] = data[\"cs\"][:15_000]\n",
    "print(\"Unique tokens in english 30k dataset:\", len(set(data[\"en\"])))\n",
    "print(\"Unique tokens in czech 15k dataset:\", len(set(data[\"cs\"])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b130e5a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "English tokens with at least 50 occurrences: 73\n",
      "Czech tokens with at least 20 occurrences: 77\n"
     ]
    }
   ],
   "source": [
    "uni = {lang: get_unigrams(data[lang]) for lang in data}\n",
    "bi = {lang: get_bigrams(data[lang]) for lang in data}\n",
    "\n",
    "print(\"English tokens with at least 50 occurrences:\", len([token for token, count in uni[\"en\"].items() if count >= 50]))\n",
    "print(\"Czech tokens with at least 20 occurrences:\", len([token for token, count in uni[\"cs\"].items() if count >= 20]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e3955a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current number of classes: 73, MI=0.719245\n"
     ]
    }
   ],
   "source": [
    "def get_class_bigrams(word2class, bigrams):\n",
    "    class_bigrams = defaultdict(int)\n",
    "    for (w1, w2), count in bigrams.items():\n",
    "        c1, c2 = word2class[w1], word2class[w2]\n",
    "        class_bigrams[(c1, c2)] += count\n",
    "    return class_bigrams\n",
    "\n",
    "def get_class_bigrams_matrix(word2class, bigrams):\n",
    "    class_bigrams_matrix = np.zeros((len(word2class), len(word2class)), dtype=int)\n",
    "    for (l, r), count in bigrams.items():\n",
    "        if l not in word2class or r not in word2class:\n",
    "            continue\n",
    "        c1, c2 = word2class[l], word2class[r]\n",
    "        class_bigrams_matrix[c1, c2] += count\n",
    "    return class_bigrams_matrix\n",
    "\n",
    "def q(classes_matrix,l,r,N): # q_k(l,r)\n",
    "    c_k = classes_matrix[l,r]\n",
    "    c_kl = classes_matrix[l,:].sum()\n",
    "    c_kr = classes_matrix[:,r].sum()\n",
    "    if c_kl == 0 or c_kr == 0 or c_k == 0:\n",
    "        return 0.0\n",
    "    return c_k / N * np.log(N * c_k / (c_kl * c_kr))\n",
    "\n",
    "def merge_matrix(m, a, b):\n",
    "    \"\"\"\n",
    "    Return a new class bigram matrix where classes a and b are merged.\n",
    "    \"\"\"\n",
    "    if a > b:\n",
    "        a, b = b, a\n",
    "\n",
    "    # new merged row / column\n",
    "    new_row = m[a, :] + m[b, :]\n",
    "    new_col = m[:, a] + m[:, b]\n",
    "\n",
    "    # remove a and b\n",
    "    m2 = np.delete(m, [a, b], axis=0)\n",
    "    m2 = np.delete(m2, [a, b], axis=1)\n",
    "\n",
    "    # append merged row and column\n",
    "    m2 = np.vstack([m2, new_row[np.newaxis, :-2]])\n",
    "    new_col = np.append(new_col[:-2], new_row[-2])\n",
    "    m2 = np.column_stack([m2, new_col])\n",
    "\n",
    "    return m2\n",
    "\n",
    "\n",
    "def apply_merge_word2class(word2class, a, b):\n",
    "    \"\"\"\n",
    "    Merge class b into class a.\n",
    "    Re-label classes to keep them contiguous.\n",
    "    \"\"\"\n",
    "    new_word2class = {}\n",
    "    for w, c in word2class.items():\n",
    "        if c == b:\n",
    "            new_word2class[w] = a\n",
    "        elif c > b:\n",
    "            new_word2class[w] = c - 1\n",
    "        else:\n",
    "            new_word2class[w] = c\n",
    "    return new_word2class\n",
    "\n",
    "def mutual_information(classes_matrix, N):\n",
    "    mi = 0\n",
    "    for i in range(classes_matrix.shape[0]):\n",
    "        for j in range(classes_matrix.shape[1]):\n",
    "            mi += q(classes_matrix, i, j, N)\n",
    "    return mi\n",
    "\n",
    "\n",
    "def word_classes(initial_words, unigrams, bigrams, target_number=15):\n",
    "    N = sum(unigrams.values()) # total number of tokens\n",
    "    word2class = {w:i for i, (w,count) in enumerate(initial_words.items())} # r function word2class[word] = class_id\n",
    "    # class_bigrams_dict = get_class_bigrams(word2class, bigrams)\n",
    "    class_bigrams_matrix = get_class_bigrams_matrix(word2class, bigrams) # i,j position -> #bigrams s.t. class i-> class j\n",
    "    \n",
    "    mi = mutual_information(class_bigrams_matrix, N)\n",
    "\n",
    "    while class_bigrams_matrix.shape[0] > target_number:\n",
    "        print(f\"Current number of classes: {class_bigrams_matrix.shape[0]}, MI={mi:.6f}\")\n",
    "\n",
    "        best_loss = float(\"inf\")\n",
    "        best_pair = None\n",
    "        best_matrix = None\n",
    "\n",
    "        K = class_bigrams_matrix.shape[0]\n",
    "\n",
    "        for a in range(K):\n",
    "            for b in range(a + 1, K):\n",
    "                # test merge\n",
    "                merged_matrix = merge_matrix(class_bigrams_matrix, a, b)\n",
    "                merged_mi = mutual_information(merged_matrix, N)\n",
    "                loss = mi - merged_mi\n",
    "\n",
    "                if loss < best_loss:\n",
    "                    best_loss = loss\n",
    "                    best_pair = (a, b)\n",
    "                    best_matrix = merged_matrix\n",
    "\n",
    "        # apply best merge\n",
    "        a, b = best_pair\n",
    "        class_bigrams_matrix = best_matrix\n",
    "        word2class = apply_merge_word2class(word2class, a, b)\n",
    "        mi -= best_loss\n",
    "\n",
    "        print(\n",
    "            f\"Merged classes {a} and {b}, \"\n",
    "            f\"loss={best_loss:.6f}, \"\n",
    "            f\"remaining={class_bigrams_matrix.shape[0]}\"\n",
    "        )\n",
    "\n",
    "\n",
    "    return class_bigrams_matrix, word2class\n",
    "\n",
    "\n",
    "\n",
    "m, w2c = word_classes({w:c for w,c in get_unigrams(data[\"en\"]).items() if c >= 50}, get_unigrams(data[\"en\"]), get_bigrams(data[\"en\"]), target_number=15)\n",
    "\n",
    "# mi = 0\n",
    "# N = sum(get_unigrams(data[\"en\"]).values())\n",
    "# for i in range(m.shape[0]):\n",
    "#     for j in range(m.shape[1]):\n",
    "#         mi += q(m, i, j, N)\n",
    "# print(mi)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "38cc9b0e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "73"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(w2c.values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0a36634a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "73"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(w2c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "c5f932b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['že']"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[a for a,b in w2c.items() if b == 181]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "7dcdc05a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([38]), array([181]))"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.where(m == 144)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "90342bbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !wget \"https://ufallab.ms.mff.cuni.cz/~helcl/npfl147/cc.en.50.bin\"\n",
    "# !wget \"https://ufallab.ms.mff.cuni.cz/~helcl/npfl147/cc.cs.50.bin\"\n",
    "# import fasttext\n",
    "# ft_en = fasttext.load_model('cc.en.50.bin')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv_nlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
