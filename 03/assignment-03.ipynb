{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7308f743",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: stanza in /mnt/disk/patrik/nlp/.venv_nlp/lib/python3.10/site-packages (1.11.0)\n",
      "Requirement already satisfied: numpy in /mnt/disk/patrik/nlp/.venv_nlp/lib/python3.10/site-packages (from stanza) (2.2.6)\n",
      "Requirement already satisfied: torch>=1.13.0 in /mnt/disk/patrik/nlp/.venv_nlp/lib/python3.10/site-packages (from stanza) (2.9.1)\n",
      "Requirement already satisfied: protobuf>=3.15.0 in /mnt/disk/patrik/nlp/.venv_nlp/lib/python3.10/site-packages (from stanza) (6.33.5)\n",
      "Requirement already satisfied: tqdm in /mnt/disk/patrik/nlp/.venv_nlp/lib/python3.10/site-packages (from stanza) (4.67.1)\n",
      "Requirement already satisfied: networkx in /mnt/disk/patrik/nlp/.venv_nlp/lib/python3.10/site-packages (from stanza) (3.4.2)\n",
      "Requirement already satisfied: emoji in /mnt/disk/patrik/nlp/.venv_nlp/lib/python3.10/site-packages (from stanza) (2.15.0)\n",
      "Requirement already satisfied: requests in /mnt/disk/patrik/nlp/.venv_nlp/lib/python3.10/site-packages (from stanza) (2.32.5)\n",
      "Requirement already satisfied: tomli in /mnt/disk/patrik/nlp/.venv_nlp/lib/python3.10/site-packages (from stanza) (2.4.0)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.8.90 in /mnt/disk/patrik/nlp/.venv_nlp/lib/python3.10/site-packages (from torch>=1.13.0->stanza) (12.8.90)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.8.90 in /mnt/disk/patrik/nlp/.venv_nlp/lib/python3.10/site-packages (from torch>=1.13.0->stanza) (12.8.90)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /mnt/disk/patrik/nlp/.venv_nlp/lib/python3.10/site-packages (from torch>=1.13.0->stanza) (4.15.0)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.8.93 in /mnt/disk/patrik/nlp/.venv_nlp/lib/python3.10/site-packages (from torch>=1.13.0->stanza) (12.8.93)\n",
      "Requirement already satisfied: triton==3.5.1 in /mnt/disk/patrik/nlp/.venv_nlp/lib/python3.10/site-packages (from torch>=1.13.0->stanza) (3.5.1)\n",
      "Requirement already satisfied: nvidia-nvshmem-cu12==3.3.20 in /mnt/disk/patrik/nlp/.venv_nlp/lib/python3.10/site-packages (from torch>=1.13.0->stanza) (3.3.20)\n",
      "Requirement already satisfied: filelock in /mnt/disk/patrik/nlp/.venv_nlp/lib/python3.10/site-packages (from torch>=1.13.0->stanza) (3.20.0)\n",
      "Requirement already satisfied: jinja2 in /mnt/disk/patrik/nlp/.venv_nlp/lib/python3.10/site-packages (from torch>=1.13.0->stanza) (3.1.6)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.3.3.83 in /mnt/disk/patrik/nlp/.venv_nlp/lib/python3.10/site-packages (from torch>=1.13.0->stanza) (11.3.3.83)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.8.90 in /mnt/disk/patrik/nlp/.venv_nlp/lib/python3.10/site-packages (from torch>=1.13.0->stanza) (12.8.90)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /mnt/disk/patrik/nlp/.venv_nlp/lib/python3.10/site-packages (from torch>=1.13.0->stanza) (0.7.1)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.8.93 in /mnt/disk/patrik/nlp/.venv_nlp/lib/python3.10/site-packages (from torch>=1.13.0->stanza) (12.8.93)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.8.4.1 in /mnt/disk/patrik/nlp/.venv_nlp/lib/python3.10/site-packages (from torch>=1.13.0->stanza) (12.8.4.1)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /mnt/disk/patrik/nlp/.venv_nlp/lib/python3.10/site-packages (from torch>=1.13.0->stanza) (2.27.5)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /mnt/disk/patrik/nlp/.venv_nlp/lib/python3.10/site-packages (from torch>=1.13.0->stanza) (1.14.0)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.9.90 in /mnt/disk/patrik/nlp/.venv_nlp/lib/python3.10/site-packages (from torch>=1.13.0->stanza) (10.3.9.90)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /mnt/disk/patrik/nlp/.venv_nlp/lib/python3.10/site-packages (from torch>=1.13.0->stanza) (9.10.2.21)\n",
      "Requirement already satisfied: fsspec>=0.8.5 in /mnt/disk/patrik/nlp/.venv_nlp/lib/python3.10/site-packages (from torch>=1.13.0->stanza) (2025.10.0)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.5.8.93 in /mnt/disk/patrik/nlp/.venv_nlp/lib/python3.10/site-packages (from torch>=1.13.0->stanza) (12.5.8.93)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.7.3.90 in /mnt/disk/patrik/nlp/.venv_nlp/lib/python3.10/site-packages (from torch>=1.13.0->stanza) (11.7.3.90)\n",
      "Requirement already satisfied: nvidia-cufile-cu12==1.13.1.3 in /mnt/disk/patrik/nlp/.venv_nlp/lib/python3.10/site-packages (from torch>=1.13.0->stanza) (1.13.1.3)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /mnt/disk/patrik/nlp/.venv_nlp/lib/python3.10/site-packages (from requests->stanza) (3.11)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /mnt/disk/patrik/nlp/.venv_nlp/lib/python3.10/site-packages (from requests->stanza) (2025.11.12)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /mnt/disk/patrik/nlp/.venv_nlp/lib/python3.10/site-packages (from requests->stanza) (2.5.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /mnt/disk/patrik/nlp/.venv_nlp/lib/python3.10/site-packages (from requests->stanza) (3.4.4)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /mnt/disk/patrik/nlp/.venv_nlp/lib/python3.10/site-packages (from sympy>=1.13.3->torch>=1.13.0->stanza) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /mnt/disk/patrik/nlp/.venv_nlp/lib/python3.10/site-packages (from jinja2->torch>=1.13.0->stanza) (3.0.3)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/disk/patrik/nlp/.venv_nlp/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "%pip install stanza\n",
    "\n",
    "import stanza"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fa6bf5f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: conllu in /mnt/disk/patrik/nlp/.venv_nlp/lib/python3.10/site-packages (6.0.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install conllu\n",
    "\n",
    "from conllu import parse_incr, parse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7f38ecd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2026-02-08 16:41:04--  https://raw.githubusercontent.com/UniversalDependencies/UD_Czech-PDTC/refs/heads/master/cs_pdtc-ud-train-la.conllu\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.111.133, 185.199.109.133, 185.199.110.133, ...\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.111.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 24175776 (23M) [text/plain]\n",
      "Saving to: ‘cs_pdtc-ud-train-la.conllu’\n",
      "\n",
      "cs_pdtc-ud-train-la 100%[===================>]  23,06M  38,4MB/s    in 0,6s    \n",
      "\n",
      "2026-02-08 16:41:04 (38,4 MB/s) - ‘cs_pdtc-ud-train-la.conllu’ saved [24175776/24175776]\n",
      "\n",
      "--2026-02-08 16:41:05--  https://raw.githubusercontent.com/UniversalDependencies/UD_Czech-PDTC/refs/heads/master/cs_pdtc-ud-test.conllu\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.111.133, 185.199.108.133, 185.199.109.133, ...\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.111.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 39742361 (38M) [text/plain]\n",
      "Saving to: ‘cs_pdtc-ud-test.conllu’\n",
      "\n",
      "cs_pdtc-ud-test.con 100%[===================>]  37,90M  39,6MB/s    in 1,0s    \n",
      "\n",
      "2026-02-08 16:41:08 (39,6 MB/s) - ‘cs_pdtc-ud-test.conllu’ saved [39742361/39742361]\n",
      "\n",
      "--2026-02-08 16:41:08--  https://raw.githubusercontent.com/UniversalDependencies/UD_Czech-PDTC/refs/heads/master/cs_pdtc-ud-dev.conllu\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.110.133, 185.199.111.133, 185.199.108.133, ...\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.110.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 50117913 (48M) [text/plain]\n",
      "Saving to: ‘cs_pdtc-ud-dev.conllu’\n",
      "\n",
      "cs_pdtc-ud-dev.conl 100%[===================>]  47,80M  39,0MB/s    in 1,2s    \n",
      "\n",
      "2026-02-08 16:41:10 (39,0 MB/s) - ‘cs_pdtc-ud-dev.conllu’ saved [50117913/50117913]\n",
      "\n",
      "--2026-02-08 16:41:10--  https://raw.githubusercontent.com/UniversalDependencies/UD_English-GUM/refs/heads/master/en_gum-ud-train.conllu\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.110.133, 185.199.109.133, 185.199.111.133, ...\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.110.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 18490556 (18M) [text/plain]\n",
      "Saving to: ‘en_gum-ud-train.conllu’\n",
      "\n",
      "en_gum-ud-train.con 100%[===================>]  17,63M  41,7MB/s    in 0,4s    \n",
      "\n",
      "2026-02-08 16:41:11 (41,7 MB/s) - ‘en_gum-ud-train.conllu’ saved [18490556/18490556]\n",
      "\n",
      "--2026-02-08 16:41:12--  https://raw.githubusercontent.com/UniversalDependencies/UD_English-GUM/refs/heads/master/en_gum-ud-test.conllu\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.111.133, 185.199.108.133, 185.199.109.133, ...\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.111.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 2926279 (2,8M) [text/plain]\n",
      "Saving to: ‘en_gum-ud-test.conllu’\n",
      "\n",
      "en_gum-ud-test.conl 100%[===================>]   2,79M  --.-KB/s    in 0,1s    \n",
      "\n",
      "2026-02-08 16:41:12 (27,1 MB/s) - ‘en_gum-ud-test.conllu’ saved [2926279/2926279]\n",
      "\n",
      "--2026-02-08 16:41:12--  https://raw.githubusercontent.com/UniversalDependencies/UD_English-GUM/refs/heads/master/en_gum-ud-dev.conllu\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.110.133, 185.199.111.133, 185.199.109.133, ...\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.110.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 2924380 (2,8M) [text/plain]\n",
      "Saving to: ‘en_gum-ud-dev.conllu’\n",
      "\n",
      "en_gum-ud-dev.conll 100%[===================>]   2,79M  --.-KB/s    in 0,1s    \n",
      "\n",
      "2026-02-08 16:41:12 (27,0 MB/s) - ‘en_gum-ud-dev.conllu’ saved [2924380/2924380]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget https://raw.githubusercontent.com/UniversalDependencies/UD_Czech-PDTC/refs/heads/master/cs_pdtc-ud-train-la.conllu -O cs_pdtc-ud-train-la.conllu\n",
    "!wget https://raw.githubusercontent.com/UniversalDependencies/UD_Czech-PDTC/refs/heads/master/cs_pdtc-ud-test.conllu -O cs_pdtc-ud-test.conllu\n",
    "!wget https://raw.githubusercontent.com/UniversalDependencies/UD_Czech-PDTC/refs/heads/master/cs_pdtc-ud-dev.conllu -O cs_pdtc-ud-dev.conllu\n",
    "\n",
    "!wget https://raw.githubusercontent.com/UniversalDependencies/UD_English-GUM/refs/heads/master/en_gum-ud-train.conllu -O en_gum-ud-train.conllu\n",
    "!wget https://raw.githubusercontent.com/UniversalDependencies/UD_English-GUM/refs/heads/master/en_gum-ud-test.conllu -O en_gum-ud-test.conllu\n",
    "!wget https://raw.githubusercontent.com/UniversalDependencies/UD_English-GUM/refs/heads/master/en_gum-ud-dev.conllu -O en_gum-ud-dev.conllu\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "bd83b4ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "filenames_test = {\n",
    "    \"cs\" : \"cs_pdtc-ud-test.conllu\",\n",
    "    \"en\": \"en_gum-ud-test.conllu\"\n",
    "}\n",
    "\n",
    "filenames_dev = {\n",
    "    \"cs\" : \"cs_pdtc-ud-dev.conllu\",\n",
    "    \"en\": \"en_gum-ud-dev.conllu\"\n",
    "}\n",
    "\n",
    "filenames_train = {\n",
    "    \"cs\" : \"cs_pdtc-ud-train-la.conllu\",\n",
    "    \"en\": \"en_gum-ud-train.conllu\"\n",
    "}\n",
    "\n",
    "filenames = {\n",
    "    \"test\": filenames_test,\n",
    "    \"dev\": filenames_dev,\n",
    "    \"train\": filenames_train\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "43d8629f",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = dict()\n",
    "\n",
    "for name, d in filenames.items():\n",
    "    corpus[name] = dict()\n",
    "    for lang, filename in d.items():\n",
    "        with open(filename, \"r\") as f:\n",
    "            corpus[name][lang] = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22b0b176",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-02-08 16:41:25 INFO: Checking for updates to resources.json in case models have been updated.  Note: this behavior can be turned off with download_method=None or download_method=DownloadMethod.REUSE_RESOURCES\n",
      "Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/main/resources_1.11.0.json: 436kB [00:00, 21.9MB/s]                    \n",
      "2026-02-08 16:41:25 INFO: Downloaded file to /home/patrik/stanza_resources/resources.json\n",
      "2026-02-08 16:41:26 INFO: Loading these models for language: en (English):\n",
      "===============================\n",
      "| Processor | Package         |\n",
      "-------------------------------\n",
      "| tokenize  | combined        |\n",
      "| pos       | combined_charlm |\n",
      "===============================\n",
      "\n",
      "2026-02-08 16:41:26 INFO: Using device: cpu\n",
      "2026-02-08 16:41:26 INFO: Loading: tokenize\n",
      "2026-02-08 16:41:26 INFO: Loading: pos\n",
      "2026-02-08 16:41:36 INFO: Done loading processors!\n",
      "2026-02-08 16:41:36 INFO: Checking for updates to resources.json in case models have been updated.  Note: this behavior can be turned off with download_method=None or download_method=DownloadMethod.REUSE_RESOURCES\n",
      "Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/main/resources_1.11.0.json: 436kB [00:00, 12.6MB/s]                    \n",
      "2026-02-08 16:41:36 INFO: Downloaded file to /home/patrik/stanza_resources/resources.json\n",
      "2026-02-08 16:41:37 INFO: Loading these models for language: cs (Czech):\n",
      "============================\n",
      "| Processor | Package      |\n",
      "----------------------------\n",
      "| tokenize  | pdt          |\n",
      "| pos       | pdt_nocharlm |\n",
      "============================\n",
      "\n",
      "2026-02-08 16:41:37 INFO: Using device: cpu\n",
      "2026-02-08 16:41:37 INFO: Loading: tokenize\n",
      "2026-02-08 16:41:37 INFO: Loading: pos\n",
      "2026-02-08 16:41:41 INFO: Done loading processors!\n"
     ]
    }
   ],
   "source": [
    "nlp_en = stanza.Pipeline(lang='en', processors='tokenize,pos', tokenize_pretokenized=True)\n",
    "nlp_cs = stanza.Pipeline(lang='cs', processors='tokenize,pos', tokenize_pretokenized=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b094922",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "English train size : 177410\n",
      "Czech dev size : 384431\n",
      "Czech test size : 305808\n"
     ]
    }
   ],
   "source": [
    "def line_number_check(data, text):\n",
    "    i=0\n",
    "    for line in data.split(\"\\n\"):\n",
    "        splitted = line.split(\"\\t\")\n",
    "        if len(splitted) == 0 or splitted[0].startswith(\"#\") or \"-\" in splitted[0] or \".\" in splitted[0] or splitted[0] == \"\\n\" or splitted[0] == \"\":\n",
    "            continue\n",
    "        i += 1\n",
    "    print(f\"{text} size : {i}\")\n",
    "\n",
    "line_number_check(corpus[\"train\"][\"en\"], \"English train\")\n",
    "line_number_check(corpus[\"dev\"][\"cs\"], \"Czech dev\")\n",
    "line_number_check(corpus[\"test\"][\"cs\"], \"Czech test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47fbabd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "English test size : 28397\n",
      "English test word-tag pairs : 6166\n",
      "Czech test size : 22844\n",
      "Czech test word-tag pairs : 9234\n"
     ]
    }
   ],
   "source": [
    "def word_tag_count(data, text):\n",
    "    word_tag_pairs = set()\n",
    "    i = 0\n",
    "    for line in data.split(\"\\n\"):\n",
    "        splitted = line.split(\"\\t\")\n",
    "        if len(splitted) == 0 or splitted[0].startswith(\"#\") or \"-\" in splitted[0] or \".\" in splitted[0] or splitted[0] == \"\\n\" or splitted[0] == \"\":\n",
    "            continue\n",
    "        word_tag_pairs.add((splitted[1], splitted[4]))\n",
    "        i+=1\n",
    "\n",
    "    print(f\"{text} size : {i}\")\n",
    "    # print(f\"{text} word-tag pairs : {len(word_tag_pairs)}\")\n",
    "\n",
    "word_tag_count(corpus[\"test\"][\"en\"], \"English test\")\n",
    "word_tag_count(\"\\n\\n\".join(corpus[\"test\"][\"cs\"].split(\"\\n\\n\")[:1500]), \"Czech test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "31b2028b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BEFORE TRUNCATION TO 1_500 SENTENCES\n",
      "test-cs sentence count: 20187 word/tag pairs (lines): 305808\n",
      "test-en sentence count: 1464 word/tag pairs (lines): 28397\n",
      "dev-cs sentence count: 22666 word/tag pairs (lines): 384431\n",
      "dev-en sentence count: 1575 word/tag pairs (lines): 28119\n",
      "train-cs sentence count: 12519 word/tag pairs (lines): 218409\n",
      "train-en sentence count: 10224 word/tag pairs (lines): 177410\n"
     ]
    }
   ],
   "source": [
    "import conllu\n",
    "\n",
    "def tagize(filename, text, max_sentences=999_999_999):\n",
    "    tokens = []\n",
    "    tags = []\n",
    "    sentence_count=0\n",
    "    tag_count = 0\n",
    "    with open (filename, \"r\") as f:\n",
    "        for sentence in conllu.parse_incr(f):\n",
    "            if sentence_count >= max_sentences:\n",
    "                break\n",
    "            sentence_count += 1\n",
    "            for token in sentence:\n",
    "                if isinstance(token[\"id\"], (list, tuple)) and (\".\" in token[\"id\"] or \"-\" in token[\"id\"]):\n",
    "                    continue\n",
    "                # print(token[\"form\"], token[\"upos\"])\n",
    "                tag_count += 1\n",
    "                tokens.append(token[\"form\"])\n",
    "                tags.append(token[\"upos\"])\n",
    "    print(text, \"sentence count:\", sentence_count, \"word/tag pairs (lines):\", tag_count)\n",
    "    return tokens, tags\n",
    "\n",
    "\n",
    "print(\"BEFORE TRUNCATION TO 1_500 SENTENCES\")\n",
    "pairs = {type: {lang: tagize(filename, f\"{type}-{lang}\") for lang, filename in d.items()} for type, d in filenames.items()}\n",
    "# a,b = tagize(filenames[\"test\"][\"en\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "f80386d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRUNCATING TEST SETS\n",
      "test-cs sentence count: 1500 word/tag pairs (lines): 22844\n",
      "test-en sentence count: 1464 word/tag pairs (lines): 28397\n"
     ]
    }
   ],
   "source": [
    "print(\"TRUNCATING TEST SETS\")\n",
    "pairs[\"test\"] = {lang: tagize(filename, f\"test-{lang}\", max_sentences=1500) for lang, filename in filenames[\"test\"].items()}\n",
    "tokens = {type: {lang: pair[0] for lang, pair in d.items()} for type, d in pairs.items()}\n",
    "tags = {type: {lang: pair[1] for lang, pair in d.items()} for type, d in pairs.items()}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv_nlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
