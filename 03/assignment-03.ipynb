{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fa6bf5f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: conllu in /mnt/disk/patrik/nlp/.venv_nlp/lib/python3.10/site-packages (6.0.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: stanza in /mnt/disk/patrik/nlp/.venv_nlp/lib/python3.10/site-packages (1.11.0)\n",
      "Requirement already satisfied: protobuf>=3.15.0 in /mnt/disk/patrik/nlp/.venv_nlp/lib/python3.10/site-packages (from stanza) (6.33.5)\n",
      "Requirement already satisfied: requests in /mnt/disk/patrik/nlp/.venv_nlp/lib/python3.10/site-packages (from stanza) (2.32.5)\n",
      "Requirement already satisfied: networkx in /mnt/disk/patrik/nlp/.venv_nlp/lib/python3.10/site-packages (from stanza) (3.4.2)\n",
      "Requirement already satisfied: numpy in /mnt/disk/patrik/nlp/.venv_nlp/lib/python3.10/site-packages (from stanza) (2.2.6)\n",
      "Requirement already satisfied: torch>=1.13.0 in /mnt/disk/patrik/nlp/.venv_nlp/lib/python3.10/site-packages (from stanza) (2.9.1)\n",
      "Requirement already satisfied: tqdm in /mnt/disk/patrik/nlp/.venv_nlp/lib/python3.10/site-packages (from stanza) (4.67.1)\n",
      "Requirement already satisfied: tomli in /mnt/disk/patrik/nlp/.venv_nlp/lib/python3.10/site-packages (from stanza) (2.4.0)\n",
      "Requirement already satisfied: emoji in /mnt/disk/patrik/nlp/.venv_nlp/lib/python3.10/site-packages (from stanza) (2.15.0)\n",
      "Requirement already satisfied: jinja2 in /mnt/disk/patrik/nlp/.venv_nlp/lib/python3.10/site-packages (from torch>=1.13.0->stanza) (3.1.6)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /mnt/disk/patrik/nlp/.venv_nlp/lib/python3.10/site-packages (from torch>=1.13.0->stanza) (1.14.0)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.8.93 in /mnt/disk/patrik/nlp/.venv_nlp/lib/python3.10/site-packages (from torch>=1.13.0->stanza) (12.8.93)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.9.90 in /mnt/disk/patrik/nlp/.venv_nlp/lib/python3.10/site-packages (from torch>=1.13.0->stanza) (10.3.9.90)\n",
      "Requirement already satisfied: nvidia-nvshmem-cu12==3.3.20 in /mnt/disk/patrik/nlp/.venv_nlp/lib/python3.10/site-packages (from torch>=1.13.0->stanza) (3.3.20)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.8.90 in /mnt/disk/patrik/nlp/.venv_nlp/lib/python3.10/site-packages (from torch>=1.13.0->stanza) (12.8.90)\n",
      "Requirement already satisfied: fsspec>=0.8.5 in /mnt/disk/patrik/nlp/.venv_nlp/lib/python3.10/site-packages (from torch>=1.13.0->stanza) (2025.10.0)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /mnt/disk/patrik/nlp/.venv_nlp/lib/python3.10/site-packages (from torch>=1.13.0->stanza) (0.7.1)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.8.93 in /mnt/disk/patrik/nlp/.venv_nlp/lib/python3.10/site-packages (from torch>=1.13.0->stanza) (12.8.93)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.3.3.83 in /mnt/disk/patrik/nlp/.venv_nlp/lib/python3.10/site-packages (from torch>=1.13.0->stanza) (11.3.3.83)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /mnt/disk/patrik/nlp/.venv_nlp/lib/python3.10/site-packages (from torch>=1.13.0->stanza) (4.15.0)\n",
      "Requirement already satisfied: triton==3.5.1 in /mnt/disk/patrik/nlp/.venv_nlp/lib/python3.10/site-packages (from torch>=1.13.0->stanza) (3.5.1)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.8.90 in /mnt/disk/patrik/nlp/.venv_nlp/lib/python3.10/site-packages (from torch>=1.13.0->stanza) (12.8.90)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.5.8.93 in /mnt/disk/patrik/nlp/.venv_nlp/lib/python3.10/site-packages (from torch>=1.13.0->stanza) (12.5.8.93)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.8.90 in /mnt/disk/patrik/nlp/.venv_nlp/lib/python3.10/site-packages (from torch>=1.13.0->stanza) (12.8.90)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.8.4.1 in /mnt/disk/patrik/nlp/.venv_nlp/lib/python3.10/site-packages (from torch>=1.13.0->stanza) (12.8.4.1)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /mnt/disk/patrik/nlp/.venv_nlp/lib/python3.10/site-packages (from torch>=1.13.0->stanza) (2.27.5)\n",
      "Requirement already satisfied: filelock in /mnt/disk/patrik/nlp/.venv_nlp/lib/python3.10/site-packages (from torch>=1.13.0->stanza) (3.20.0)\n",
      "Requirement already satisfied: nvidia-cufile-cu12==1.13.1.3 in /mnt/disk/patrik/nlp/.venv_nlp/lib/python3.10/site-packages (from torch>=1.13.0->stanza) (1.13.1.3)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.7.3.90 in /mnt/disk/patrik/nlp/.venv_nlp/lib/python3.10/site-packages (from torch>=1.13.0->stanza) (11.7.3.90)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /mnt/disk/patrik/nlp/.venv_nlp/lib/python3.10/site-packages (from torch>=1.13.0->stanza) (9.10.2.21)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /mnt/disk/patrik/nlp/.venv_nlp/lib/python3.10/site-packages (from requests->stanza) (2.5.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /mnt/disk/patrik/nlp/.venv_nlp/lib/python3.10/site-packages (from requests->stanza) (3.4.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /mnt/disk/patrik/nlp/.venv_nlp/lib/python3.10/site-packages (from requests->stanza) (3.11)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /mnt/disk/patrik/nlp/.venv_nlp/lib/python3.10/site-packages (from requests->stanza) (2025.11.12)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /mnt/disk/patrik/nlp/.venv_nlp/lib/python3.10/site-packages (from sympy>=1.13.3->torch>=1.13.0->stanza) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /mnt/disk/patrik/nlp/.venv_nlp/lib/python3.10/site-packages (from jinja2->torch>=1.13.0->stanza) (3.0.3)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/disk/patrik/nlp/.venv_nlp/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "%pip install conllu\n",
    "%pip install stanza\n",
    "\n",
    "import conllu\n",
    "import pandas as pd\n",
    "import stanza\n",
    "from collections import defaultdict, Counter\n",
    "from itertools import pairwise\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7f38ecd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2026-02-09 21:25:31--  https://raw.githubusercontent.com/UniversalDependencies/UD_Czech-PDTC/refs/heads/master/cs_pdtc-ud-train-la.conllu\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.109.133, 185.199.111.133, 185.199.108.133, ...\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.109.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 24175776 (23M) [text/plain]\n",
      "Saving to: ‘cs_pdtc-ud-train-la.conllu’\n",
      "\n",
      "cs_pdtc-ud-train-la 100%[===================>]  23,06M  46,8MB/s    in 0,5s    \n",
      "\n",
      "2026-02-09 21:25:33 (46,8 MB/s) - ‘cs_pdtc-ud-train-la.conllu’ saved [24175776/24175776]\n",
      "\n",
      "--2026-02-09 21:25:33--  https://raw.githubusercontent.com/UniversalDependencies/UD_Czech-PDTC/refs/heads/master/cs_pdtc-ud-test.conllu\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.111.133, 185.199.109.133, 185.199.108.133, ...\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.111.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 39742361 (38M) [text/plain]\n",
      "Saving to: ‘cs_pdtc-ud-test.conllu’\n",
      "\n",
      "cs_pdtc-ud-test.con 100%[===================>]  37,90M  49,2MB/s    in 0,8s    \n",
      "\n",
      "2026-02-09 21:25:35 (49,2 MB/s) - ‘cs_pdtc-ud-test.conllu’ saved [39742361/39742361]\n",
      "\n",
      "--2026-02-09 21:25:36--  https://raw.githubusercontent.com/UniversalDependencies/UD_Czech-PDTC/refs/heads/master/cs_pdtc-ud-dev.conllu\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.109.133, 185.199.110.133, 185.199.108.133, ...\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.109.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 50117913 (48M) [text/plain]\n",
      "Saving to: ‘cs_pdtc-ud-dev.conllu’\n",
      "\n",
      "cs_pdtc-ud-dev.conl 100%[===================>]  47,80M  46,9MB/s    in 1,0s    \n",
      "\n",
      "2026-02-09 21:25:39 (46,9 MB/s) - ‘cs_pdtc-ud-dev.conllu’ saved [50117913/50117913]\n",
      "\n",
      "--2026-02-09 21:25:39--  https://raw.githubusercontent.com/UniversalDependencies/UD_English-GUM/refs/heads/master/en_gum-ud-train.conllu\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.110.133, 185.199.109.133, 185.199.108.133, ...\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.110.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 18490556 (18M) [text/plain]\n",
      "Saving to: ‘en_gum-ud-train.conllu’\n",
      "\n",
      "en_gum-ud-train.con 100%[===================>]  17,63M  39,0MB/s    in 0,5s    \n",
      "\n",
      "2026-02-09 21:25:40 (39,0 MB/s) - ‘en_gum-ud-train.conllu’ saved [18490556/18490556]\n",
      "\n",
      "--2026-02-09 21:25:40--  https://raw.githubusercontent.com/UniversalDependencies/UD_English-GUM/refs/heads/master/en_gum-ud-test.conllu\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.109.133, 185.199.110.133, 185.199.108.133, ...\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.109.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 2926279 (2,8M) [text/plain]\n",
      "Saving to: ‘en_gum-ud-test.conllu’\n",
      "\n",
      "en_gum-ud-test.conl 100%[===================>]   2,79M  --.-KB/s    in 0,1s    \n",
      "\n",
      "2026-02-09 21:25:41 (23,9 MB/s) - ‘en_gum-ud-test.conllu’ saved [2926279/2926279]\n",
      "\n",
      "--2026-02-09 21:25:41--  https://raw.githubusercontent.com/UniversalDependencies/UD_English-GUM/refs/heads/master/en_gum-ud-dev.conllu\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.110.133, 185.199.109.133, ...\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 2924380 (2,8M) [text/plain]\n",
      "Saving to: ‘en_gum-ud-dev.conllu’\n",
      "\n",
      "en_gum-ud-dev.conll 100%[===================>]   2,79M  --.-KB/s    in 0,1s    \n",
      "\n",
      "2026-02-09 21:25:41 (24,4 MB/s) - ‘en_gum-ud-dev.conllu’ saved [2924380/2924380]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget https://raw.githubusercontent.com/UniversalDependencies/UD_Czech-PDTC/refs/heads/master/cs_pdtc-ud-train-la.conllu -O cs_pdtc-ud-train-la.conllu\n",
    "!wget https://raw.githubusercontent.com/UniversalDependencies/UD_Czech-PDTC/refs/heads/master/cs_pdtc-ud-test.conllu -O cs_pdtc-ud-test.conllu\n",
    "!wget https://raw.githubusercontent.com/UniversalDependencies/UD_Czech-PDTC/refs/heads/master/cs_pdtc-ud-dev.conllu -O cs_pdtc-ud-dev.conllu\n",
    "\n",
    "!wget https://raw.githubusercontent.com/UniversalDependencies/UD_English-GUM/refs/heads/master/en_gum-ud-train.conllu -O en_gum-ud-train.conllu\n",
    "!wget https://raw.githubusercontent.com/UniversalDependencies/UD_English-GUM/refs/heads/master/en_gum-ud-test.conllu -O en_gum-ud-test.conllu\n",
    "!wget https://raw.githubusercontent.com/UniversalDependencies/UD_English-GUM/refs/heads/master/en_gum-ud-dev.conllu -O en_gum-ud-dev.conllu\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bd83b4ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "filenames_test = {\n",
    "    \"cs\" : \"cs_pdtc-ud-test.conllu\",\n",
    "    \"en\": \"en_gum-ud-test.conllu\"\n",
    "}\n",
    "\n",
    "filenames_dev = {\n",
    "    \"cs\" : \"cs_pdtc-ud-dev.conllu\",\n",
    "    \"en\": \"en_gum-ud-dev.conllu\"\n",
    "}\n",
    "\n",
    "filenames_train = {\n",
    "    \"cs\" : \"cs_pdtc-ud-train-la.conllu\",\n",
    "    \"en\": \"en_gum-ud-train.conllu\"\n",
    "}\n",
    "\n",
    "filenames = {\n",
    "    \"test\": filenames_test,\n",
    "    \"dev\": filenames_dev,\n",
    "    \"train\": filenames_train\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "43d8629f",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = dict()\n",
    "\n",
    "for name, d in filenames.items():\n",
    "    corpus[name] = dict()\n",
    "    for lang, filename in d.items():\n",
    "        with open(filename, \"r\") as f:\n",
    "            corpus[name][lang] = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "22b0b176",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-02-09 21:25:43 INFO: Checking for updates to resources.json in case models have been updated.  Note: this behavior can be turned off with download_method=None or download_method=DownloadMethod.REUSE_RESOURCES\n",
      "Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/main/resources_1.11.0.json: 436kB [00:00, 14.2MB/s]                    \n",
      "2026-02-09 21:25:43 INFO: Downloaded file to /home/patrik/stanza_resources/resources.json\n",
      "2026-02-09 21:25:45 INFO: Loading these models for language: en (English):\n",
      "===============================\n",
      "| Processor | Package         |\n",
      "-------------------------------\n",
      "| tokenize  | combined        |\n",
      "| pos       | combined_charlm |\n",
      "===============================\n",
      "\n",
      "2026-02-09 21:25:45 INFO: Using device: cpu\n",
      "2026-02-09 21:25:45 INFO: Loading: tokenize\n",
      "2026-02-09 21:25:45 INFO: Loading: pos\n",
      "2026-02-09 21:25:51 INFO: Done loading processors!\n",
      "2026-02-09 21:25:51 INFO: Checking for updates to resources.json in case models have been updated.  Note: this behavior can be turned off with download_method=None or download_method=DownloadMethod.REUSE_RESOURCES\n",
      "Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/main/resources_1.11.0.json: 436kB [00:00, 17.2MB/s]                    \n",
      "2026-02-09 21:25:51 INFO: Downloaded file to /home/patrik/stanza_resources/resources.json\n",
      "2026-02-09 21:25:52 INFO: Loading these models for language: cs (Czech):\n",
      "============================\n",
      "| Processor | Package      |\n",
      "----------------------------\n",
      "| tokenize  | pdt          |\n",
      "| pos       | pdt_nocharlm |\n",
      "============================\n",
      "\n",
      "2026-02-09 21:25:52 INFO: Using device: cpu\n",
      "2026-02-09 21:25:52 INFO: Loading: tokenize\n",
      "2026-02-09 21:25:52 INFO: Loading: pos\n",
      "2026-02-09 21:25:56 INFO: Done loading processors!\n"
     ]
    }
   ],
   "source": [
    "nlp_en = stanza.Pipeline(lang='en', processors='tokenize,pos', tokenize_pretokenized=True)\n",
    "nlp_cs = stanza.Pipeline(lang='cs', processors='tokenize,pos', tokenize_pretokenized=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0b094922",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MANUAL FUNCTIONS - FOR DEBUGGING AND STUFF - NOT USED CURRENTLY\n",
    "\n",
    "def line_number_check(data, text):\n",
    "    i=0\n",
    "    for line in data.split(\"\\n\"):\n",
    "        splitted = line.split(\"\\t\")\n",
    "        if len(splitted) == 0 or splitted[0].startswith(\"#\") or \"-\" in splitted[0] or \".\" in splitted[0] or splitted[0] == \"\\n\" or splitted[0] == \"\":\n",
    "            continue\n",
    "        i += 1\n",
    "    print(f\"{text} size : {i}\")\n",
    "\n",
    "\n",
    "def word_tag_count(data, text):\n",
    "    word_tag_pairs = set()\n",
    "    i = 0\n",
    "    for line in data.split(\"\\n\"):\n",
    "        splitted = line.split(\"\\t\")\n",
    "        if len(splitted) == 0 or splitted[0].startswith(\"#\") or \"-\" in splitted[0] or \".\" in splitted[0] or splitted[0] == \"\\n\" or splitted[0] == \"\":\n",
    "            continue\n",
    "        word_tag_pairs.add((splitted[1], splitted[4]))\n",
    "        i+=1\n",
    "\n",
    "    print(f\"{text} size : {i}\")\n",
    "\n",
    "def word_tag_count(data, text):\n",
    "    word_tag_pairs = set()\n",
    "    i = 0\n",
    "    for line in data.split(\"\\n\"):\n",
    "        splitted = line.split(\"\\t\")\n",
    "        if len(splitted) == 0 or splitted[0].startswith(\"#\") or \"-\" in splitted[0] or \".\" in splitted[0] or splitted[0] == \"\\n\" or splitted[0] == \"\":\n",
    "            continue\n",
    "        word_tag_pairs.add((splitted[1], splitted[4]))\n",
    "        i+=1\n",
    "\n",
    "    print(f\"{text} size : {i}\")\n",
    "    # print(f\"{text} word-tag pairs : {len(word_tag_pairs)}\")\n",
    "\n",
    "# line_number_check(corpus[\"train\"][\"en\"], \"English train\")\n",
    "# line_number_check(corpus[\"dev\"][\"cs\"], \"Czech dev\")\n",
    "# line_number_check(corpus[\"test\"][\"cs\"], \"Czech test\")\n",
    "\n",
    "# word_tag_count(corpus[\"test\"][\"en\"], \"English test\")\n",
    "# word_tag_count(\"\\n\\n\".join(corpus[\"test\"][\"cs\"].split(\"\\n\\n\")[:1500]), \"Czech test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "31b2028b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BEFORE TRUNCATION TO 1_500 SENTENCES\n",
      "test-cs sentence count: 20187 word/tag pairs (lines): 305808\n",
      "test-en sentence count: 1464 word/tag pairs (lines): 28397\n",
      "dev-cs sentence count: 22666 word/tag pairs (lines): 384431\n",
      "dev-en sentence count: 1575 word/tag pairs (lines): 28119\n",
      "train-cs sentence count: 12519 word/tag pairs (lines): 218409\n",
      "train-en sentence count: 10224 word/tag pairs (lines): 177410\n"
     ]
    }
   ],
   "source": [
    "def tagize(filename, text, max_sentences=999_999_999):\n",
    "    tokens = []\n",
    "    tags = []\n",
    "    sentence_count=0\n",
    "    tag_count = 0\n",
    "    with open (filename, \"r\") as f:\n",
    "        for sentence in conllu.parse_incr(f):\n",
    "            sentence_tokens = []\n",
    "            sentence_tags = []\n",
    "            if sentence_count >= max_sentences:\n",
    "                break\n",
    "            for token in sentence:\n",
    "                if isinstance(token[\"id\"], (list, tuple)) and (\".\" in token[\"id\"] or \"-\" in token[\"id\"]):\n",
    "                    continue\n",
    "                # print(token[\"form\"], token[\"upos\"])\n",
    "                tag_count += 1\n",
    "                sentence_tokens.append(token[\"form\"])\n",
    "                sentence_tags.append(token[\"upos\"])\n",
    "            \n",
    "            sentence_count += 1\n",
    "            tokens.append(sentence_tokens)\n",
    "            tags.append(sentence_tags)\n",
    "    print(text, \"sentence count:\", sentence_count, \"word/tag pairs (lines):\", tag_count)\n",
    "    return tokens, tags\n",
    "\n",
    "\n",
    "print(\"BEFORE TRUNCATION TO 1_500 SENTENCES\")\n",
    "pairs = {type: {lang: tagize(filename, f\"{type}-{lang}\") for lang, filename in d.items()} for type, d in filenames.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f80386d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRUNCATING TEST SETS\n",
      "test-cs sentence count: 1500 word/tag pairs (lines): 22844\n",
      "test-en sentence count: 1464 word/tag pairs (lines): 28397\n"
     ]
    }
   ],
   "source": [
    "print(\"TRUNCATING TEST SETS\")\n",
    "pairs[\"test\"] = {lang: tagize(filename, f\"test-{lang}\", max_sentences=1500) for lang, filename in filenames[\"test\"].items()}\n",
    "tokens = {type: {lang: pair[0] for lang, pair in d.items()} for type, d in pairs.items()}\n",
    "tags = {type: {lang: pair[1] for lang, pair in d.items()} for type, d in pairs.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f2d70054",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_en = nlp_en(tokens[\"test\"][\"en\"])\n",
    "doc_cs = nlp_cs(tokens[\"test\"][\"cs\"][:1500])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "56efcb11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stanza EN test accuracy: 97.8308%\n",
      "Stanza EN confusion matrix below\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>pred</th>\n",
       "      <th>ADJ</th>\n",
       "      <th>ADP</th>\n",
       "      <th>ADV</th>\n",
       "      <th>AUX</th>\n",
       "      <th>CCONJ</th>\n",
       "      <th>DET</th>\n",
       "      <th>INTJ</th>\n",
       "      <th>NOUN</th>\n",
       "      <th>NUM</th>\n",
       "      <th>PART</th>\n",
       "      <th>PRON</th>\n",
       "      <th>PROPN</th>\n",
       "      <th>PUNCT</th>\n",
       "      <th>SCONJ</th>\n",
       "      <th>SYM</th>\n",
       "      <th>VERB</th>\n",
       "      <th>X</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gold</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ADJ</th>\n",
       "      <td>1755</td>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>34</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ADP</th>\n",
       "      <td>0</td>\n",
       "      <td>2833</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ADV</th>\n",
       "      <td>37</td>\n",
       "      <td>36</td>\n",
       "      <td>1226</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AUX</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1520</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CCONJ</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>987</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DET</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2515</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>INTJ</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>155</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NOUN</th>\n",
       "      <td>25</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>4806</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>59</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NUM</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>478</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PART</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>668</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PRON</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2178</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PROPN</th>\n",
       "      <td>40</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1677</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PUNCT</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3547</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SCONJ</th>\n",
       "      <td>0</td>\n",
       "      <td>22</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>438</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SYM</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>VERB</th>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>33</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2951</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>X</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "pred    ADJ   ADP   ADV   AUX  CCONJ   DET  INTJ  NOUN  NUM  PART  PRON  \\\n",
       "gold                                                                      \n",
       "ADJ    1755     2    11     0      0     0     0    34    0     0     0   \n",
       "ADP       0  2833    12     0      2     0     0     0    0     1     0   \n",
       "ADV      37    36  1226     0      0    14     6     8    0     0     3   \n",
       "AUX       0     0     0  1520      0     0     0     0    0     0     0   \n",
       "CCONJ     0     0     0     0    987     0     0     0    0     0     0   \n",
       "DET       0     0     1     0      3  2515     1     0    0     0     1   \n",
       "INTJ      1     4    12     0      1     0   155     2    0     0     0   \n",
       "NOUN     25     0     0     1      0     0     2  4806    3     0     1   \n",
       "NUM       0     1     0     0      0     0     0     0  478     0     0   \n",
       "PART      0     1     0     1      0     1     0     0    0   668     0   \n",
       "PRON      0     0     0     0      0     2     0     1    0     0  2178   \n",
       "PROPN    40     1     0     0      0     1     1    64    2     0     0   \n",
       "PUNCT     0     0     0     0      0     0     0     0    0     2     0   \n",
       "SCONJ     0    22     1     0      0     0     0     0    0     0     7   \n",
       "SYM       0     0     0     0      0     0     0     5    0     0     0   \n",
       "VERB     23     0     0    12      0     0     1    33    0     0     0   \n",
       "X         0     0     0     0      0     0     0     3    4     0     0   \n",
       "\n",
       "pred   PROPN  PUNCT  SCONJ  SYM  VERB   X  \n",
       "gold                                       \n",
       "ADJ       13      0      0    0    18   0  \n",
       "ADP        2      0     15    0     0   0  \n",
       "ADV        1      0      4    0     1   0  \n",
       "AUX        0      0      0    0    13   0  \n",
       "CCONJ      0      0      1    0     0   0  \n",
       "DET        0      0      0    0     0   0  \n",
       "INTJ       1      0      3    0     2   3  \n",
       "NOUN      59      0      0    0     8   1  \n",
       "NUM        0      0      0    0     0   0  \n",
       "PART       0      0      0    0     0   0  \n",
       "PRON       0      0      6    0     0   0  \n",
       "PROPN   1677      0      0    0     1   0  \n",
       "PUNCT      0   3547      0    1     0   0  \n",
       "SCONJ      0      0    438    0     0   0  \n",
       "SYM        0      2      0   29     0   0  \n",
       "VERB       0      0      0    0  2951   0  \n",
       "X          8      0      0    0     0  18  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stanza CS test accuracy: 97.2903%\n",
      "Stanza CS confusion matrix below\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>pred</th>\n",
       "      <th>ADJ</th>\n",
       "      <th>ADP</th>\n",
       "      <th>ADV</th>\n",
       "      <th>AUX</th>\n",
       "      <th>CCONJ</th>\n",
       "      <th>DET</th>\n",
       "      <th>INTJ</th>\n",
       "      <th>NOUN</th>\n",
       "      <th>NUM</th>\n",
       "      <th>PART</th>\n",
       "      <th>PRON</th>\n",
       "      <th>PROPN</th>\n",
       "      <th>PUNCT</th>\n",
       "      <th>SCONJ</th>\n",
       "      <th>SYM</th>\n",
       "      <th>VERB</th>\n",
       "      <th>X</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gold</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ADJ</th>\n",
       "      <td>2572</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ADP</th>\n",
       "      <td>0</td>\n",
       "      <td>2109</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ADV</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>878</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AUX</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>774</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CCONJ</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>731</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DET</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>916</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>INTJ</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NOUN</th>\n",
       "      <td>12</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>5525</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>32</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NUM</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>616</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PART</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>230</td>\n",
       "      <td>0</td>\n",
       "      <td>79</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>160</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PRON</th>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>730</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PROPN</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>36</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1026</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PUNCT</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3461</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SCONJ</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>438</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SYM</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>38</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>VERB</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2148</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>X</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>89</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "pred    ADJ   ADP  ADV  AUX  CCONJ  DET  INTJ  NOUN  NUM  PART  PRON  PROPN  \\\n",
       "gold                                                                          \n",
       "ADJ    2572     0    1    0      0    0     0    16    1     0     0     11   \n",
       "ADP       0  2109    0    0      0    0     0     3    0     0     1      0   \n",
       "ADV       1     2  878    0     16    1     0    10    0     5     3      0   \n",
       "AUX       0     0    0  774      0    0     0     0    0     0     0      0   \n",
       "CCONJ     0     0   12    0    731    0     0     0    0     2     0      0   \n",
       "DET       1     0    1    0      0  916     0     0    0     0     0      0   \n",
       "INTJ      0     0    0    0      0    0    14     2    0     3     0      1   \n",
       "NOUN     12     3    7    0      4    0     4  5525    0     0     0     32   \n",
       "NUM       0     0    0    0      0    0     0     0  616     0     0      0   \n",
       "PART      0     0  230    0     79    0     2     2    0   160     0      0   \n",
       "PRON      1     6    0    4      0   14     0     4    0     0   730      0   \n",
       "PROPN     2     0    0    0      0    0     3    36    0     0     3   1026   \n",
       "PUNCT     0     0    0    0      0    0     0     0    0     0     0      0   \n",
       "SCONJ     0     0    7    0      0    0     0     0    0     2     3      0   \n",
       "SYM       0     0    0    0      0    0     0     3    0     0     0      0   \n",
       "VERB      1     0    0    0      0    0     0     4    0     0     0      4   \n",
       "X         0     0    0    0      0    0     0     3    0     0     0     17   \n",
       "\n",
       "pred   PUNCT  SCONJ  SYM  VERB   X  \n",
       "gold                                \n",
       "ADJ        0      0    0     0   1  \n",
       "ADP        0      0    0     1   0  \n",
       "ADV        0      0    0     1   0  \n",
       "AUX        0      0    0     2   0  \n",
       "CCONJ      0     11    0     0   0  \n",
       "DET        0      0    0     1   0  \n",
       "INTJ       0      0    0     0   0  \n",
       "NOUN       0      0    6     3   4  \n",
       "NUM        0      0    0     0   0  \n",
       "PART       0      2    0     0   0  \n",
       "PRON       0      0    0     0   0  \n",
       "PROPN      0      0    0     1   1  \n",
       "PUNCT   3461      0    0     0   0  \n",
       "SCONJ      0    438    0     0   0  \n",
       "SYM        0      0   38     0   0  \n",
       "VERB       0      0    0  2148   0  \n",
       "X          0      0    0     0  89  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def stanza_eval(doc, tokens_sents, gold_sents):\n",
    "    \"\"\"tokens_sents: List[List[str]], gold_sents: List[List[str]] (UPOS)\"\"\"\n",
    "    pred_sents = [[w.upos for w in s.words] for s in doc.sentences]\n",
    "\n",
    "    # accuracy\n",
    "    correct = total = 0\n",
    "    for g, p in zip(gold_sents, pred_sents):\n",
    "        if len(g) != len(p):\n",
    "            raise ValueError(f\"Length mismatch in a sentence: gold={len(g)} pred={len(p)} \"\n",
    "                             \"(check MWT/ellipsis filtering + tokenize_pretokenized=True)\")\n",
    "        for gt, pt in zip(g, p):\n",
    "            total += 1\n",
    "            correct += (gt == pt)\n",
    "    acc = 100.0 * correct / total\n",
    "\n",
    "    # confusion matrix (rows=gold, cols=pred)\n",
    "    gflat = [t for sent in gold_sents for t in sent]\n",
    "    pflat = [t for sent in pred_sents for t in sent]\n",
    "    cm = pd.crosstab(pd.Series(gflat, name=\"gold\"), pd.Series(pflat, name=\"pred\"))\n",
    "    return acc, cm\n",
    "\n",
    "en_acc, en_cm = stanza_eval(doc_en, tokens[\"test\"][\"en\"], tags[\"test\"][\"en\"])\n",
    "print(f\"Stanza EN test accuracy: {en_acc:.4f}%\")\n",
    "print(\"Stanza EN confusion matrix below\")\n",
    "display(en_cm)\n",
    "\n",
    "cs_acc, cs_cm = stanza_eval(doc_cs, tokens[\"test\"][\"cs\"][:1500], tags[\"test\"][\"cs\"][:1500])\n",
    "print(f\"Stanza CS test accuracy: {cs_acc:.4f}%\")\n",
    "print(\"Stanza CS confusion matrix below\")\n",
    "display(cs_cm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "36100994",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRUNKATING CS DEV SET\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dev-cs sentence count: 1500 word/tag pairs (lines): 21752\n"
     ]
    }
   ],
   "source": [
    "print(\"TRUNKATING CS DEV SET\")\n",
    "tokens[\"dev\"][\"cs\"], tags[\"dev\"][\"cs\"] = tagize(filenames[\"dev\"][\"cs\"], \"dev-cs\", max_sentences=1500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "708c4c32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sizes check\n",
      "test-cs tokenized sentences: 1500 tokens : 22844\n",
      "test-en tokenized sentences: 1464 tokens : 28397\n",
      "dev-cs tokenized sentences: 1500 tokens : 21752\n",
      "dev-en tokenized sentences: 1575 tokens : 28119\n",
      "train-cs tokenized sentences: 12519 tokens : 218409\n",
      "train-en tokenized sentences: 10224 tokens : 177410\n"
     ]
    }
   ],
   "source": [
    "# Check sizes\n",
    "print(\"Sizes check\")\n",
    "for type, d in tokens.items():\n",
    "    for lang, sents in d.items():\n",
    "        print(f\"{type}-{lang} tokenized sentences: {len(sents)} tokens : {sum(len(s) for s in sents)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bf75a19",
   "metadata": {},
   "source": [
    "# Transition model smoothing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8be7afeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "BOS = \"<s>\"\n",
    "EOS = \"</s>\"\n",
    "\n",
    "# UPDATED BIGRAMS SO THERE IS ALSO start_symbol followed by start_symbol (and also end followed by end)\n",
    "get_unigrams = lambda tokens : Counter(tokens + [EOS])\n",
    "get_bigrams = lambda tokens : Counter(zip(2 * [BOS] + tokens + [EOS], [BOS] + tokens + 2 * [EOS]))\n",
    "get_trigrams = lambda tokens : Counter(zip(2 * [BOS] + tokens, [BOS] + tokens + [EOS], tokens + 2 * [EOS]))\n",
    "\n",
    "def get_all_ngrams(tokens_or_tags, n=1):\n",
    "    ngrams = {\n",
    "        1: get_unigrams,\n",
    "        2: get_bigrams,\n",
    "        3: get_trigrams\n",
    "    }[n]\n",
    "    all = Counter()    \n",
    "    for sentence in tokens_or_tags:\n",
    "        all.update(ngrams(sentence))\n",
    "    return all\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "95e8d8ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# COPIED FROM THE FIRST ASSIGNMENT\n",
    "# NOT IDEA IF THIS IS CORRECT SINCE I REVIECED NO FEEDBACK :)\n",
    "# BUT I GOT 92 POINTS SO HOPEFULLY THIS IS OK\n",
    "\n",
    "def bigram_probab(bigrams, unigrams, wi, wi_1):\n",
    "    c2 = bigrams[(wi_1, wi)]#  if (wi_1, wi) in bigrams else 0\n",
    "    c1 = unigrams[wi_1]# if wi_1 in unigrams else 0\n",
    "    if c1 == 0:\n",
    "        return 1 / len(unigrams)\n",
    "    return c2 / c1\n",
    "\n",
    "def trigram_probab(trigrams, bigrams, unigrams, wi, wi_1, wi_2):\n",
    "    c3 = trigrams[(wi_2, wi_1, wi)]# if (wi_2, wi_1, wi) in trigrams else 0\n",
    "    c2 = bigrams[(wi_2, wi_1)]# if (wi_2, wi_1) in bigrams else 0\n",
    "    if c2 == 0:\n",
    "        return 1 / len(unigrams)\n",
    "    return c3 / c2\n",
    "\n",
    "def smoothed_probab_trigram(trigrams, bigrams, unigrams, wi, wi_1, wi_2, lambdas, N_uni = None):\n",
    "    N_uni = sum(unigrams.values()) if N_uni == None else N_uni\n",
    "    lambda0, lambda1, lambda2, lambda3 = lambdas\n",
    "    p0 = 1 / len(unigrams)\n",
    "    p1 = unigrams[wi] / N_uni# if wi in unigrams else 1 / sum(unigrams.values())\n",
    "    p2 = bigram_probab(bigrams, unigrams, wi, wi_1)\n",
    "    p3 = trigram_probab(trigrams, bigrams, unigrams, wi, wi_1, wi_2)\n",
    "    return lambda0 * p0 + lambda1 * p1 + lambda2 * p2 + lambda3 * p3\n",
    "\n",
    "\n",
    "def EM_smoothing(train, heldout, max_iter=100, e = 1e-4):\n",
    "    lambdas = [0.25, 0.25, 0.25, 0.25]\n",
    "\n",
    "    # --- ONE MINOR CHANGE FROM THE FIRST ASSIGNMENT ---\n",
    "    # trigrams_heldout = get_trigrams(heldout)\n",
    "    # bigrams_heldout = get_bigrams(heldout)\n",
    "    # unigrams_heldout = get_unigrams(heldout)\n",
    "\n",
    "    # trigrams_train = get_trigrams(train)\n",
    "    # bigrams_train = get_bigrams(train)\n",
    "    # unigrams_train = get_unigrams(train)\n",
    "\n",
    "    trigrams_heldout = get_all_ngrams(heldout, n=3)\n",
    "    bigrams_heldout = get_all_ngrams(heldout, n=2)\n",
    "    unigrams_heldout = get_all_ngrams(heldout, n=1)\n",
    "\n",
    "    trigrams_train = get_all_ngrams(train, n=3)\n",
    "    bigrams_train = get_all_ngrams(train, n=2)\n",
    "    unigrams_train = get_all_ngrams(train, n=1)\n",
    "    # --- --- ----- ------ ---- --- ----- ---------- ---\n",
    "\n",
    "    N_uni = sum(unigrams_train.values()) # saves a lot of time lol\n",
    "\n",
    "    iter = 0\n",
    "    while iter < max_iter:\n",
    "        counts = [0.0, 0.0, 0.0, 0.0]\n",
    "\n",
    "        for (wi_2, wi_1, wi), c in trigrams_heldout.items():\n",
    "            p0 = 1 / len(unigrams_train)\n",
    "            p1 = unigrams_train[wi] / N_uni# if wi in unigrams_train else 1 / N_uni\n",
    "            p2 = bigram_probab(bigrams_train, unigrams_train, wi, wi_1)\n",
    "            p3 = trigram_probab(trigrams_train, bigrams_train, unigrams_train, wi, wi_1, wi_2)\n",
    "\n",
    "            p_total = lambdas[0] * p0 + lambdas[1] * p1 + lambdas[2] * p2 + lambdas[3] * p3\n",
    "\n",
    "            counts[0] += c * (lambdas[0] * p0) / p_total\n",
    "            counts[1] += c * (lambdas[1] * p1) / p_total\n",
    "            counts[2] += c * (lambdas[2] * p2) / p_total\n",
    "            counts[3] += c * (lambdas[3] * p3) / p_total\n",
    "\n",
    "        new_lambdas = [count / sum(counts) for count in counts]\n",
    "\n",
    "        # print(\"Iteration \", iter, \" lambdas: \", new_lambdas)\n",
    "\n",
    "        if all(abs(new_lambdas[i] - lambdas[i]) < e for i in range(4)):\n",
    "            break\n",
    "\n",
    "        lambdas = new_lambdas\n",
    "        iter += 1\n",
    "    return lambdas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b85b587f",
   "metadata": {},
   "outputs": [],
   "source": [
    "ngrams_train_tag = {type: {i: {lang: get_all_ngrams(tags[\"train\"][lang], n=i) for lang in tags[\"train\"]} for i in range(1, 4)} for type in tags[\"train\"]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2cb73bab",
   "metadata": {},
   "outputs": [],
   "source": [
    "em_lambdas = {lang: EM_smoothing(tags[\"train\"][lang], tags[\"dev\"][lang]) for lang in tags[\"train\"]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "63155b07",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'cs': [0.005635399093115278,\n",
       "  0.005527962553778706,\n",
       "  0.10105815981569118,\n",
       "  0.8877784785374149],\n",
       " 'en': [0.00012675633014343153,\n",
       "  0.0033791000786512265,\n",
       "  0.08104221881633325,\n",
       "  0.915451924774872]}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "em_lambdas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fce9f70d",
   "metadata": {},
   "source": [
    "# Emission model smoothing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "acf9af4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "import math\n",
    "\n",
    "UNK = \"<UNK>\"\n",
    "\n",
    "def train_lexical_model(tokens_train, tags_train, tokens_dev, tags_dev,\n",
    "                        unk_threshold=1, add_alpha=0.0, eps=1e-6, max_iter=80):\n",
    "    \"\"\"\n",
    "    Learns interpolated emission model with UNK:\n",
    "\n",
    "      P(w|t) = λ0 * 1/|V|  +  λ1 * P(w)  +  λ2 * P_MLE(w|t)\n",
    "\n",
    "    - UNK: words with train freq <= unk_threshold become <UNK> in training,\n",
    "           unseen words at decode time also become <UNK>.\n",
    "    - Lambdas (λ0,λ1,λ2) learned on DEV with EM-like expected-counts updates.\n",
    "\n",
    "    Returns dict with:\n",
    "      - logp_emit(tag, word): log P(word|tag)\n",
    "      - lambdas: [λ0, λ1, λ2]\n",
    "      - vocab: normalized vocab (includes <UNK>)\n",
    "    \"\"\"\n",
    "\n",
    "    # --- TRAIN vocab + UNK mapping ---\n",
    "    wf = Counter(w for sent in tokens_train for w in sent)\n",
    "\n",
    "    def norm_train(w):\n",
    "        return w if wf[w] > unk_threshold else UNK\n",
    "\n",
    "    emit = Counter()         # (t, w)\n",
    "    tag_count = Counter()    # t\n",
    "    word_count = Counter()   # w\n",
    "    vocab = {UNK}\n",
    "    total = 0\n",
    "\n",
    "    for words, tags in zip(tokens_train, tags_train):\n",
    "        for w, t in zip(words, tags):\n",
    "            w2 = norm_train(w)\n",
    "            vocab.add(w2)\n",
    "            emit[(t, w2)] += 1\n",
    "            tag_count[t] += 1\n",
    "            word_count[w2] += 1\n",
    "            total += 1\n",
    "\n",
    "    V = len(vocab)\n",
    "\n",
    "    def p0(w):  # uniform over vocab\n",
    "        return 1.0 / V\n",
    "\n",
    "    def p1(w):  # unigram P(w)\n",
    "        denom = total + add_alpha * V\n",
    "        return (word_count[w] + add_alpha) / denom if denom else 0.0\n",
    "\n",
    "    def p2(t, w):  # MLE P(w|t)\n",
    "        denom = tag_count[t] + add_alpha * V\n",
    "        return (emit[(t, w)] + add_alpha) / denom if denom else 0.0\n",
    "\n",
    "    def norm_dev(w):\n",
    "        # unseen -> UNK\n",
    "        return w if w in vocab else UNK\n",
    "\n",
    "    # --- learn lambdas on DEV ---\n",
    "    lambdas = [1/3, 1/3, 1/3]\n",
    "    for _ in range(max_iter):\n",
    "        exp = [0.0, 0.0, 0.0]\n",
    "\n",
    "        for words, tags in zip(tokens_dev, tags_dev):\n",
    "            for w_raw, t in zip(words, tags):\n",
    "                w = norm_dev(w_raw)\n",
    "                probs = [p0(w), p1(w), p2(t, w)]\n",
    "                mix = [lambdas[i] * probs[i] for i in range(3)]\n",
    "                Z = sum(mix)\n",
    "                if Z <= 0:\n",
    "                    continue\n",
    "                exp[0] += mix[0] / Z\n",
    "                exp[1] += mix[1] / Z\n",
    "                exp[2] += mix[2] / Z\n",
    "\n",
    "        s = sum(exp)\n",
    "        new_lambdas = [e / s for e in exp] if s else lambdas\n",
    "        if max(abs(new_lambdas[i] - lambdas[i]) for i in range(3)) < eps:\n",
    "            lambdas = new_lambdas\n",
    "            break\n",
    "        lambdas = new_lambdas\n",
    "\n",
    "    def logp_emit(t, w_raw):\n",
    "        w = w_raw if w_raw in vocab else UNK\n",
    "        p = lambdas[0] * p0(w) + lambdas[1] * p1(w) + lambdas[2] * p2(t, w)\n",
    "        return -math.inf if p <= 0.0 else math.log(p)\n",
    "\n",
    "    return {\"vocab\": vocab, \"lambdas\": lambdas, \"logp_emit\": logp_emit,\n",
    "            \"emit\": emit, \"tag_count\": tag_count, \"word_count\": word_count}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "02ba48d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "lex = {}\n",
    "for lang in [\"en\", \"cs\"]:\n",
    "    lex[lang] = train_lexical_model(\n",
    "        tokens[\"train\"][lang], tags[\"train\"][lang],\n",
    "        tokens[\"dev\"][lang],   tags[\"dev\"][lang],\n",
    "        unk_threshold=1, add_alpha=0.0\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b387a7b",
   "metadata": {},
   "source": [
    "# HMM/Viterbi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "24f678a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def build_tag_index(tagset, BOS=\"<s>\", EOS=\"</s>\"):\n",
    "    tags = [t for t in tagset if t not in (BOS, EOS)]\n",
    "    idx = {t:i for i,t in enumerate(tags)}\n",
    "    return tags, idx\n",
    "\n",
    "def precompute_trans_tensor(tags, logp_trans, BOS=\"<s>\", EOS=\"</s>\"):\n",
    "    \"\"\"\n",
    "    Returns:\n",
    "      A: (T+1, T+1, T) where indices 0..T-1 are real tags, index T is BOS2\n",
    "      end1: (T, T) for log P(EOS | u,v)\n",
    "      end2: (T,) for log P(EOS | v, EOS) or log P(EOS | v, EOS) depending on your transition definition\n",
    "    \"\"\"\n",
    "    T = len(tags)\n",
    "    BOSi = T  # extra index for BOS\n",
    "    A = np.full((T+1, T+1, T), -np.inf, dtype=np.float64)\n",
    "\n",
    "    # transitions to real tags\n",
    "    for ui in range(T+1):\n",
    "        u = BOS if ui == BOSi else tags[ui]\n",
    "        for vi in range(T+1):\n",
    "            v = BOS if vi == BOSi else tags[vi]\n",
    "            for ci in range(T):\n",
    "                c = tags[ci]\n",
    "                A[ui, vi, ci] = logp_trans(u, v, c)\n",
    "\n",
    "    # termination pieces\n",
    "    end1 = np.full((T, T), -np.inf, dtype=np.float64)  # log P(EOS | u,v)\n",
    "    end2 = np.full((T,), -np.inf, dtype=np.float64)    # log P(EOS | v, EOS) or log P(EOS | v, EOS)\n",
    "    for ui in range(T):\n",
    "        u = tags[ui]\n",
    "        for vi in range(T):\n",
    "            v = tags[vi]\n",
    "            end1[ui, vi] = logp_trans(u, v, EOS)\n",
    "    for vi in range(T):\n",
    "        v = tags[vi]\n",
    "        end2[vi] = logp_trans(v, EOS, EOS)\n",
    "\n",
    "    return A, end1, end2, BOSi\n",
    "\n",
    "def viterbi_trigram_fast(words, tagset, logp_trans, logp_emit, BOS=\"<s>\", EOS=\"</s>\"):\n",
    "    \"\"\"\n",
    "    Trigram Viterbi in numpy. Same result as your Python version, much faster.\n",
    "    \"\"\"\n",
    "    if not words:\n",
    "        return []\n",
    "\n",
    "    tags, idx = build_tag_index(tagset, BOS=BOS, EOS=EOS)\n",
    "    T = len(tags)\n",
    "\n",
    "    A, end1, end2, BOSi = precompute_trans_tensor(tags, logp_trans, BOS=BOS, EOS=EOS)\n",
    "\n",
    "    # dp[pp, p] corresponds to best score ending with (t_{i-1}=pp, t_i=p) at current position i\n",
    "    dp = np.full((T+1, T+1), -np.inf, dtype=np.float64)\n",
    "    dp[BOSi, BOSi] = 0.0\n",
    "\n",
    "    # backpointers: for each position i store argmax over pp for each (p,c)\n",
    "    bps = []\n",
    "\n",
    "    for w in words:\n",
    "        emit = np.array([logp_emit(t, w) for t in tags], dtype=np.float64)  # (T,)\n",
    "        # scores[pp, p, c] = dp[pp,p] + A[pp,p,c] + emit[c]\n",
    "        scores = dp[:, :, None] + A + emit[None, None, :]\n",
    "        # maximize over pp dimension -> new_dp[p,c]\n",
    "        new_dp = np.max(scores, axis=0)  # (T+1, T) but only p in 0..T and c in 0..T-1\n",
    "        arg_pp = np.argmax(scores, axis=0)  # same shape\n",
    "\n",
    "        # next dp should be over (p,c) pairs => dp_next[p,c]\n",
    "        dp = np.full((T+1, T+1), -np.inf, dtype=np.float64)\n",
    "        dp[:, :T] = new_dp  # dp[p, c] lives in dp[p, c]\n",
    "        bps.append(arg_pp)  # store argmax pp for each (p,c)\n",
    "\n",
    "    # termination: choose best (u,v) among real tags (0..T-1)\n",
    "    # dp[u,v] currently stored in dp[u,v] where both are in 0..T-1\n",
    "    best_score = -np.inf\n",
    "    best_u = best_v = 0\n",
    "    for u in range(T):\n",
    "        for v in range(T):\n",
    "            s = dp[u, v] + end1[u, v] + end2[v]\n",
    "            if s > best_score:\n",
    "                best_score = s\n",
    "                best_u, best_v = u, v\n",
    "\n",
    "    # backtrack\n",
    "    n = len(words)\n",
    "    out = [None] * n\n",
    "    if n == 1:\n",
    "        out[0] = tags[best_v]\n",
    "        return out\n",
    "\n",
    "    out[-2] = tags[best_u]\n",
    "    out[-1] = tags[best_v]\n",
    "\n",
    "    u, v = best_u, best_v\n",
    "    for i in range(n-1, 1, -1):\n",
    "        # bps[i] corresponds to word i+1 (1-indexed); we need arg_pp for (p=u?, c=v?)\n",
    "        arg_pp = bps[i][u, v]  # argmax pp for this (u,v)\n",
    "        out[i-2] = tags[arg_pp] if arg_pp < T else BOS\n",
    "        v, u = u, arg_pp  # shift window backwards\n",
    "\n",
    "    return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c201eee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def take_first_n_pairs(tokens_sents, tags_sents, n_pairs):\n",
    "    out_tok, out_tag = [], []\n",
    "    seen = 0\n",
    "    for words, tags in zip(tokens_sents, tags_sents):\n",
    "        if seen >= n_pairs:\n",
    "            break\n",
    "        need = n_pairs - seen\n",
    "        if len(words) <= need:\n",
    "            out_tok.append(words)\n",
    "            out_tag.append(tags)\n",
    "            seen += len(words)\n",
    "        else:\n",
    "            out_tok.append(words[:need])\n",
    "            out_tag.append(tags[:need])\n",
    "            seen += need\n",
    "            break\n",
    "    return out_tok, out_tag\n",
    "\n",
    "def build_logp_trans_from_train_tags(lang, tags_train_sents):\n",
    "    uni = get_all_ngrams(tags_train_sents, n=1)\n",
    "    bi  = get_all_ngrams(tags_train_sents, n=2)\n",
    "    tri = get_all_ngrams(tags_train_sents, n=3)\n",
    "    N_uni = sum(uni.values())\n",
    "    lambdas = em_lambdas[lang]\n",
    "\n",
    "    def logp_trans(u, v, t):\n",
    "        p = smoothed_probab_trigram(tri, bi, uni, wi=t, wi_1=v, wi_2=u, lambdas=lambdas, N_uni=N_uni)\n",
    "        return -math.inf if p <= 0.0 else math.log(p)\n",
    "\n",
    "    tagset = [t for t in uni.keys() if t not in (BOS, EOS)]\n",
    "    return logp_trans, tagset\n",
    "\n",
    "def eval_tagging(gold_sents, pred_sents):\n",
    "    gold_flat, pred_flat = [], []\n",
    "    for i, (g, p) in enumerate(zip(gold_sents, pred_sents)):\n",
    "        if len(g) != len(p):\n",
    "            raise ValueError(f\"Sentence {i} length mismatch: gold={len(g)} pred={len(p)}\")\n",
    "        gold_flat.extend(g)\n",
    "        pred_flat.extend(p)\n",
    "    acc = 100.0 * sum(gt == pt for gt, pt in zip(gold_flat, pred_flat)) / len(gold_flat)\n",
    "    cm = pd.crosstab(pd.Series(gold_flat, name=\"gold\"), pd.Series(pred_flat, name=\"pred\"))\n",
    "    return acc, cm\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c6683f06",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_supervised_hmm(lang, tokens_train, tags_train, tokens_dev, tags_dev,\n",
    "                         unk_threshold=1, add_alpha=0.0):\n",
    "    # transitions (use your existing interpolation lambdas em_lambdas[lang])\n",
    "    logp_trans, tagset = build_logp_trans_from_train_tags(lang, tags_train)\n",
    "\n",
    "    # lexical model (interpolated, lambdas learned on dev)\n",
    "    lex_model = train_lexical_model(tokens_train, tags_train, tokens_dev, tags_dev,\n",
    "                                    unk_threshold=unk_threshold, add_alpha=add_alpha)\n",
    "    return logp_trans, tagset, lex_model\n",
    "\n",
    "def decode_and_eval(lang, tokens_sents, gold_tags_sents, logp_trans, tagset, lex_model):\n",
    "    pred = [\n",
    "        viterbi_trigram_fast(sent, tagset, logp_trans, lex_model[\"logp_emit\"], BOS=BOS, EOS=EOS)\n",
    "        for sent in tokens_sents\n",
    "    ]\n",
    "    acc, cm = eval_tagging(gold_tags_sents, pred)\n",
    "    return acc, cm, pred\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ddf888f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FULL supervised HMM EN test accuracy: 90.8969\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>pred</th>\n",
       "      <th>ADJ</th>\n",
       "      <th>ADP</th>\n",
       "      <th>ADV</th>\n",
       "      <th>AUX</th>\n",
       "      <th>CCONJ</th>\n",
       "      <th>DET</th>\n",
       "      <th>INTJ</th>\n",
       "      <th>NOUN</th>\n",
       "      <th>NUM</th>\n",
       "      <th>PART</th>\n",
       "      <th>PRON</th>\n",
       "      <th>PROPN</th>\n",
       "      <th>PUNCT</th>\n",
       "      <th>SCONJ</th>\n",
       "      <th>SYM</th>\n",
       "      <th>VERB</th>\n",
       "      <th>X</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gold</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ADJ</th>\n",
       "      <td>1557</td>\n",
       "      <td>1</td>\n",
       "      <td>36</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>97</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>87</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>46</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ADP</th>\n",
       "      <td>0</td>\n",
       "      <td>2756</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>33</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>33</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ADV</th>\n",
       "      <td>49</td>\n",
       "      <td>49</td>\n",
       "      <td>1102</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>33</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AUX</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1492</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>34</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CCONJ</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>970</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DET</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2443</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>37</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>INTJ</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>152</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NOUN</th>\n",
       "      <td>124</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>4305</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>300</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>129</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NUM</th>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>28</td>\n",
       "      <td>365</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>62</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PART</th>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>640</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PRON</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2101</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>67</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PROPN</th>\n",
       "      <td>85</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>202</td>\n",
       "      <td>25</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1400</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>38</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PUNCT</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3538</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SCONJ</th>\n",
       "      <td>0</td>\n",
       "      <td>82</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>350</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SYM</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>29</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>VERB</th>\n",
       "      <td>92</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>105</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>144</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>63</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2598</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>X</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "pred    ADJ   ADP   ADV   AUX  CCONJ   DET  INTJ  NOUN  NUM  PART  PRON  \\\n",
       "gold                                                                      \n",
       "ADJ    1557     1    36     0      0     0     2    97    1     0     0   \n",
       "ADP       0  2756    29     0      2     0     2     1    0    33     0   \n",
       "ADV      49    49  1102     0      0    13    33    31    0     0    18   \n",
       "AUX       0     0     0  1492      0     0     0     6    0     1     0   \n",
       "CCONJ     0     0     5     0    970    12     0     0    0     0     0   \n",
       "DET       2     1    23     0      5  2443     4     3    0     0    37   \n",
       "INTJ      1     3     9     0      0     0   152     1    3     0     0   \n",
       "NOUN    124     1    16     1      0     1     5  4305    5     0     2   \n",
       "NUM      11     0     1     0      0     0     0    28  365     1     6   \n",
       "PART      1    11     2    13      0     1     0     0    0   640     0   \n",
       "PRON      0     0     1     0      0     4     0     2    0     5  2101   \n",
       "PROPN    85     1     4     0      0     1     4   202   25     0     1   \n",
       "PUNCT     0     0     0     0      0     0     0     0    0     1     0   \n",
       "SCONJ     0    82     8     0      1     6     0     0    0     5    14   \n",
       "SYM       1     0     0     0      0     0     0     1    0     0     0   \n",
       "VERB     92     2     5   105      0     0     2   144    3     0     0   \n",
       "X         1     0     0     0      0     0     0     2    1     1     0   \n",
       "\n",
       "pred   PROPN  PUNCT  SCONJ  SYM  VERB   X  \n",
       "gold                                       \n",
       "ADJ       87      1      0    0    46   5  \n",
       "ADP        4      0     33    0     4   1  \n",
       "ADV       17      0      6    0    17   1  \n",
       "AUX        0      0      0    0    34   0  \n",
       "CCONJ      0      0      1    0     0   0  \n",
       "DET        0      0      2    0     1   0  \n",
       "INTJ       3      1      4    0     6   1  \n",
       "NOUN     300      1      0    0   129  16  \n",
       "NUM       62      0      0    0     2   3  \n",
       "PART       0      3      0    0     0   0  \n",
       "PRON       5      0     67    0     1   1  \n",
       "PROPN   1400      0      0    0    38  26  \n",
       "PUNCT      0   3538      0   11     0   0  \n",
       "SCONJ      0      0    350    0     2   0  \n",
       "SYM        0      4      0   29     1   0  \n",
       "VERB      63      0      0    0  2598   6  \n",
       "X         13      0      0    0     1  14  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EN lexical lambdas: [0.004517766102101085, 0.00020438802734153852, 0.9952778458705575]\n",
      "FULL supervised HMM CS test accuracy: 88.2507\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>pred</th>\n",
       "      <th>ADJ</th>\n",
       "      <th>ADP</th>\n",
       "      <th>ADV</th>\n",
       "      <th>AUX</th>\n",
       "      <th>CCONJ</th>\n",
       "      <th>DET</th>\n",
       "      <th>INTJ</th>\n",
       "      <th>NOUN</th>\n",
       "      <th>NUM</th>\n",
       "      <th>PART</th>\n",
       "      <th>PRON</th>\n",
       "      <th>PROPN</th>\n",
       "      <th>PUNCT</th>\n",
       "      <th>SCONJ</th>\n",
       "      <th>SYM</th>\n",
       "      <th>VERB</th>\n",
       "      <th>X</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gold</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ADJ</th>\n",
       "      <td>2323</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>120</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>39</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>112</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ADP</th>\n",
       "      <td>1</td>\n",
       "      <td>2078</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ADV</th>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>761</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>26</td>\n",
       "      <td>0</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AUX</th>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>749</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CCONJ</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "      <td>728</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DET</th>\n",
       "      <td>34</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>871</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>INTJ</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NOUN</th>\n",
       "      <td>391</td>\n",
       "      <td>10</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>4787</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>200</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>152</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NUM</th>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "      <td>519</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>33</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PART</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>165</td>\n",
       "      <td>0</td>\n",
       "      <td>75</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>221</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PRON</th>\n",
       "      <td>4</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>707</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PROPN</th>\n",
       "      <td>83</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>186</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>729</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PUNCT</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3458</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SCONJ</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>443</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SYM</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>34</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>VERB</th>\n",
       "      <td>210</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>173</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1710</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>X</th>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>26</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "pred    ADJ   ADP  ADV  AUX  CCONJ  DET  INTJ  NOUN  NUM  PART  PRON  PROPN  \\\n",
       "gold                                                                          \n",
       "ADJ    2323     1    1    0      1    0     0   120    1     0     0     39   \n",
       "ADP       1  2078    0    0      0    0     0     2    0     0    30      0   \n",
       "ADV      29     0  761    0     15    1     0    35    0     2     8      9   \n",
       "AUX       8     0    0  749      0    0     0     6    0     0     2      0   \n",
       "CCONJ     1     0   17    0    728    0     0     1    1     1     0      0   \n",
       "DET      34     0    1    0      0  871     0     5    0     0     0      1   \n",
       "INTJ      0     0    0    0      0    0     3     0    0     0     0     12   \n",
       "NOUN    391    10    6    0     11    0     3  4787   16     0     0    200   \n",
       "NUM      30     0    0    0      0    0     0    30  519     0     0     33   \n",
       "PART      1     0  165    0     75    1     0     2    0   221     0      4   \n",
       "PRON      4    11    0    8      0   14     0     9    0     0   707      0   \n",
       "PROPN    83     0    0    0      0    0     0   186   22     0     0    729   \n",
       "PUNCT     1     0    0    0      0    0     0     1    1     0     0      0   \n",
       "SCONJ     0     0    2    0      2    0     0     0    0     3     0      0   \n",
       "SYM       1     0    0    0      0    0     0     6    0     0     0      0   \n",
       "VERB    210     0    3    0      0    1     0   173    1     0     0     50   \n",
       "X        21     0    0    0      0    0     0    26    0     0     0     21   \n",
       "\n",
       "pred   PUNCT  SCONJ  SYM  VERB   X  \n",
       "gold                                \n",
       "ADJ        0      0    0   112   4  \n",
       "ADP        0      0    0     2   1  \n",
       "ADV        0     26    0    31   0  \n",
       "AUX        0      0    0    11   0  \n",
       "CCONJ      0      6    0     1   0  \n",
       "DET        1      0    0     6   0  \n",
       "INTJ       0      0    0     3   2  \n",
       "NOUN       0      0    0   152  24  \n",
       "NUM        0      0    0     4   0  \n",
       "PART       0      4    0     2   0  \n",
       "PRON       1      4    0     1   0  \n",
       "PROPN      0      0    0    30  22  \n",
       "PUNCT   3458      0    0     0   0  \n",
       "SCONJ      0    443    0     0   0  \n",
       "SYM        0      0   34     0   0  \n",
       "VERB       0      0    0  1710   9  \n",
       "X          0      0    0     2  39  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CS lexical lambdas: [3.5398104972372755e-07, 0.010711851767798203, 0.9892877942511521]\n"
     ]
    }
   ],
   "source": [
    "# English full\n",
    "logp_trans_en, tagset_en, lex_en = build_supervised_hmm(\n",
    "    \"en\",\n",
    "    tokens[\"train\"][\"en\"], tags[\"train\"][\"en\"],\n",
    "    tokens[\"dev\"][\"en\"],   tags[\"dev\"][\"en\"],\n",
    "    unk_threshold=1, add_alpha=0.0\n",
    ")\n",
    "en_acc, en_cm, _ = decode_and_eval(\"en\",\n",
    "    tokens[\"test\"][\"en\"], tags[\"test\"][\"en\"],\n",
    "    logp_trans_en, tagset_en, lex_en\n",
    ")\n",
    "print(\"FULL supervised HMM EN test accuracy:\", f\"{en_acc:.4f}\")\n",
    "display(en_cm)\n",
    "print(\"EN lexical lambdas:\", lex_en[\"lambdas\"])\n",
    "\n",
    "\n",
    "# Czech full (remember: test usually first 1500 sentences)\n",
    "logp_trans_cs, tagset_cs, lex_cs = build_supervised_hmm(\n",
    "    \"cs\",\n",
    "    tokens[\"train\"][\"cs\"], tags[\"train\"][\"cs\"],\n",
    "    tokens[\"dev\"][\"cs\"],   tags[\"dev\"][\"cs\"],\n",
    "    unk_threshold=1, add_alpha=0.0\n",
    ")\n",
    "cs_acc, cs_cm, _ = decode_and_eval(\"cs\",\n",
    "    tokens[\"test\"][\"cs\"][:1500], tags[\"test\"][\"cs\"][:1500],\n",
    "    logp_trans_cs, tagset_cs, lex_cs\n",
    ")\n",
    "print(\"FULL supervised HMM CS test accuracy:\", f\"{cs_acc:.4f}\")\n",
    "display(cs_cm)\n",
    "print(\"CS lexical lambdas:\", lex_cs[\"lambdas\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2b5aafee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EN train token pairs used: 10000\n",
      "EN 10k lexical lambdas: [4.3995548351829634e-07, 0.08179960365358227, 0.9181999563909342]\n",
      "10k-init supervised HMM EN test accuracy: 70.9582\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>pred</th>\n",
       "      <th>ADJ</th>\n",
       "      <th>ADP</th>\n",
       "      <th>ADV</th>\n",
       "      <th>AUX</th>\n",
       "      <th>CCONJ</th>\n",
       "      <th>DET</th>\n",
       "      <th>INTJ</th>\n",
       "      <th>NOUN</th>\n",
       "      <th>NUM</th>\n",
       "      <th>PART</th>\n",
       "      <th>PRON</th>\n",
       "      <th>PROPN</th>\n",
       "      <th>PUNCT</th>\n",
       "      <th>SCONJ</th>\n",
       "      <th>SYM</th>\n",
       "      <th>VERB</th>\n",
       "      <th>X</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gold</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ADJ</th>\n",
       "      <td>1093</td>\n",
       "      <td>3</td>\n",
       "      <td>47</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>233</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>221</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>212</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ADP</th>\n",
       "      <td>22</td>\n",
       "      <td>2527</td>\n",
       "      <td>23</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>46</td>\n",
       "      <td>0</td>\n",
       "      <td>65</td>\n",
       "      <td>1</td>\n",
       "      <td>45</td>\n",
       "      <td>11</td>\n",
       "      <td>45</td>\n",
       "      <td>0</td>\n",
       "      <td>65</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ADV</th>\n",
       "      <td>91</td>\n",
       "      <td>57</td>\n",
       "      <td>636</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "      <td>187</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>34</td>\n",
       "      <td>134</td>\n",
       "      <td>14</td>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>128</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AUX</th>\n",
       "      <td>20</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>1158</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>48</td>\n",
       "      <td>0</td>\n",
       "      <td>52</td>\n",
       "      <td>4</td>\n",
       "      <td>106</td>\n",
       "      <td>14</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>110</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CCONJ</th>\n",
       "      <td>12</td>\n",
       "      <td>3</td>\n",
       "      <td>34</td>\n",
       "      <td>1</td>\n",
       "      <td>886</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>19</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DET</th>\n",
       "      <td>22</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>11</td>\n",
       "      <td>2345</td>\n",
       "      <td>0</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>42</td>\n",
       "      <td>31</td>\n",
       "      <td>8</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>INTJ</th>\n",
       "      <td>20</td>\n",
       "      <td>7</td>\n",
       "      <td>75</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>19</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>38</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NOUN</th>\n",
       "      <td>386</td>\n",
       "      <td>1</td>\n",
       "      <td>48</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3494</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>614</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>287</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NUM</th>\n",
       "      <td>43</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>72</td>\n",
       "      <td>226</td>\n",
       "      <td>1</td>\n",
       "      <td>21</td>\n",
       "      <td>76</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PART</th>\n",
       "      <td>8</td>\n",
       "      <td>48</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>500</td>\n",
       "      <td>0</td>\n",
       "      <td>35</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>33</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PRON</th>\n",
       "      <td>156</td>\n",
       "      <td>3</td>\n",
       "      <td>89</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>18</td>\n",
       "      <td>1</td>\n",
       "      <td>252</td>\n",
       "      <td>17</td>\n",
       "      <td>4</td>\n",
       "      <td>1121</td>\n",
       "      <td>293</td>\n",
       "      <td>6</td>\n",
       "      <td>75</td>\n",
       "      <td>1</td>\n",
       "      <td>138</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PROPN</th>\n",
       "      <td>230</td>\n",
       "      <td>2</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>614</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "      <td>22</td>\n",
       "      <td>729</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>91</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PUNCT</th>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>28</td>\n",
       "      <td>0</td>\n",
       "      <td>29</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>26</td>\n",
       "      <td>3414</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SCONJ</th>\n",
       "      <td>6</td>\n",
       "      <td>126</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>19</td>\n",
       "      <td>13</td>\n",
       "      <td>3</td>\n",
       "      <td>251</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SYM</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>VERB</th>\n",
       "      <td>198</td>\n",
       "      <td>19</td>\n",
       "      <td>71</td>\n",
       "      <td>99</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>479</td>\n",
       "      <td>14</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>364</td>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1739</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>X</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "pred    ADJ   ADP  ADV   AUX  CCONJ   DET  INTJ  NOUN  NUM  PART  PRON  PROPN  \\\n",
       "gold                                                                            \n",
       "ADJ    1093     3   47     1      1     2     0   233    5     0     0    221   \n",
       "ADP      22  2527   23     3      2     7     0    46    0    65     1     45   \n",
       "ADV      91    57  636     2      2    19     0   187   10     0    34    134   \n",
       "AUX      20     3    9  1158      2     3     0    48    0    52     4    106   \n",
       "CCONJ    12     3   34     1    886     6     0     5    0     1     6     19   \n",
       "DET      22     7    4     5     11  2345     0    22    0     0    42     31   \n",
       "INTJ     20     7   75     0      0     1     1    19    3     0     2     38   \n",
       "NOUN    386     1   48     4      0     2     0  3494   29     0     9    614   \n",
       "NUM      43     0    3     1      0     5     0    72  226     1    21     76   \n",
       "PART      8    48   32     1      0     2     0    10    0   500     0     35   \n",
       "PRON    156     3   89     5      1    18     1   252   17     4  1121    293   \n",
       "PROPN   230     2   39     1      2     0     0   614   27     0    22    729   \n",
       "PUNCT     6     5    3     4      1    28     0    29    3     7     5     26   \n",
       "SCONJ     6   126   10     3      5     3     0     8    0     5    19     13   \n",
       "SYM       2     0    0     0      1     0     0     2    1     0     0      3   \n",
       "VERB    198    19   71    99      0     1     0   479   14     4     4    364   \n",
       "X         2     1    1     0      0     0     0     3    1     0     0     11   \n",
       "\n",
       "pred   PUNCT  SCONJ  SYM  VERB   X  \n",
       "gold                                \n",
       "ADJ        4      0    2   212   9  \n",
       "ADP       11     45    0    65   3  \n",
       "ADV       14     17    1   128   4  \n",
       "AUX       14      3    0   110   1  \n",
       "CCONJ      2      0    0    13   0  \n",
       "DET        8     10    0    11   3  \n",
       "INTJ       1      2    0    11   4  \n",
       "NOUN      12      1    2   287  17  \n",
       "NUM        8      0    0    20   3  \n",
       "PART       2      0    0    33   0  \n",
       "PRON       6     75    1   138   7  \n",
       "PROPN      5      1    0    91  24  \n",
       "PUNCT   3414      0    5    12   2  \n",
       "SCONJ      3    251    0    16   0  \n",
       "SYM        6      0   18     3   0  \n",
       "VERB      12      2    0  1739  14  \n",
       "X          0      0    0     2  12  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ---- 10k SUPERVISED INIT (EN) ----\n",
    "tok10k_en, tag10k_en = take_first_n_pairs(tokens[\"train\"][\"en\"], tags[\"train\"][\"en\"], 10_000)\n",
    "print(\"EN train token pairs used:\", sum(len(s) for s in tok10k_en))\n",
    "\n",
    "# transitions built from the 10k subset (but still using em_lambdas[\"en\"])\n",
    "logp_trans_10k_en, tagset_10k_en = build_logp_trans_from_train_tags(\"en\", tag10k_en)\n",
    "\n",
    "# lexical model built from the 10k subset, lambdas learned on full dev\n",
    "lex_10k_en = train_lexical_model(tok10k_en, tag10k_en,\n",
    "                                 tokens[\"dev\"][\"en\"], tags[\"dev\"][\"en\"],\n",
    "                                 unk_threshold=1, add_alpha=0.0)\n",
    "print(\"EN 10k lexical lambdas:\", lex_10k_en[\"lambdas\"])\n",
    "\n",
    "# decode + evaluate on EN test\n",
    "en10k_acc, en10k_cm, _ = decode_and_eval(\"en\",\n",
    "    tokens[\"test\"][\"en\"], tags[\"test\"][\"en\"],\n",
    "    logp_trans_10k_en, tagset_10k_en, lex_10k_en\n",
    ")\n",
    "print(\"10k-init supervised HMM EN test accuracy:\", f\"{en10k_acc:.4f}\")\n",
    "display(en10k_cm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "fa544079",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CS train token pairs used: 10000\n",
      "CS 10k lexical lambdas: [4.044699664731544e-10, 0.0239036047924698, 0.9760963948030603]\n",
      "10k-init supervised HMM CS test accuracy: 68.3549\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>pred</th>\n",
       "      <th>ADJ</th>\n",
       "      <th>ADP</th>\n",
       "      <th>ADV</th>\n",
       "      <th>AUX</th>\n",
       "      <th>CCONJ</th>\n",
       "      <th>DET</th>\n",
       "      <th>INTJ</th>\n",
       "      <th>NOUN</th>\n",
       "      <th>NUM</th>\n",
       "      <th>PART</th>\n",
       "      <th>PRON</th>\n",
       "      <th>PROPN</th>\n",
       "      <th>PUNCT</th>\n",
       "      <th>SCONJ</th>\n",
       "      <th>SYM</th>\n",
       "      <th>VERB</th>\n",
       "      <th>X</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gold</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ADJ</th>\n",
       "      <td>1692</td>\n",
       "      <td>1</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>532</td>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>62</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>191</td>\n",
       "      <td>76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ADP</th>\n",
       "      <td>35</td>\n",
       "      <td>1992</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>24</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>36</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>18</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ADV</th>\n",
       "      <td>158</td>\n",
       "      <td>0</td>\n",
       "      <td>379</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>155</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "      <td>2</td>\n",
       "      <td>23</td>\n",
       "      <td>3</td>\n",
       "      <td>146</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AUX</th>\n",
       "      <td>21</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>694</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CCONJ</th>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>686</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DET</th>\n",
       "      <td>187</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>597</td>\n",
       "      <td>0</td>\n",
       "      <td>59</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>39</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>INTJ</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NOUN</th>\n",
       "      <td>1093</td>\n",
       "      <td>18</td>\n",
       "      <td>30</td>\n",
       "      <td>3</td>\n",
       "      <td>12</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>3580</td>\n",
       "      <td>34</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>230</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>402</td>\n",
       "      <td>173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NUM</th>\n",
       "      <td>148</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>268</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>41</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>27</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PART</th>\n",
       "      <td>32</td>\n",
       "      <td>0</td>\n",
       "      <td>115</td>\n",
       "      <td>0</td>\n",
       "      <td>78</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>27</td>\n",
       "      <td>1</td>\n",
       "      <td>158</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>36</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PRON</th>\n",
       "      <td>74</td>\n",
       "      <td>11</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>49</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>540</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>35</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PROPN</th>\n",
       "      <td>207</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>413</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>311</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>47</td>\n",
       "      <td>57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PUNCT</th>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>3420</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SCONJ</th>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>28</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>358</td>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SYM</th>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>24</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>VERB</th>\n",
       "      <td>418</td>\n",
       "      <td>1</td>\n",
       "      <td>36</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "      <td>2</td>\n",
       "      <td>636</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>60</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>923</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>X</th>\n",
       "      <td>39</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>41</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "pred    ADJ   ADP  ADV  AUX  CCONJ  DET  INTJ  NOUN  NUM  PART  PRON  PROPN  \\\n",
       "gold                                                                          \n",
       "ADJ    1692     1   22    0      1    4     0   532   17     0     1     62   \n",
       "ADP      35  1992    2    0      0    0     0    24    0     0    36      2   \n",
       "ADV     158     0  379    0      8    9     0   155    2     6     1     14   \n",
       "AUX      21     1    2  694      0    1     0    27    0     0     3      0   \n",
       "CCONJ    13     0   13    0    686    3     0    10    0     3     0      3   \n",
       "DET     187     0   13    0      0  597     0    59    1     7     0      2   \n",
       "INTJ      0     0    0    0      0    0     1     0    0     0     0     15   \n",
       "NOUN   1093    18   30    3     12    7     7  3580   34     1     4    230   \n",
       "NUM     148     0    2    0      1    0     0   100  268     0     0     41   \n",
       "PART     32     0  115    0     78    3     7    27    1   158     2     10   \n",
       "PRON     74    11    8    8      0    4     0    49    0     0   540      9   \n",
       "PROPN   207     0    6    0      0    8     0   413   21     0     0    311   \n",
       "PUNCT    23     0    0    0      0    0     0    10    1     0     0      4   \n",
       "SCONJ    14     0    8    0     28    3     0    14    0     1     0      1   \n",
       "SYM      16     0    0    0      0    0     0    24    0     0     0      0   \n",
       "VERB    418     1   36    1      1   17     2   636    8     0     4     60   \n",
       "X        39     0    0    0      0    1     0    41    0     0     0      7   \n",
       "\n",
       "pred   PUNCT  SCONJ  SYM  VERB    X  \n",
       "gold                                 \n",
       "ADJ        2      0    1   191   76  \n",
       "ADP        0      0    1    18    4  \n",
       "ADV        2     23    3   146   11  \n",
       "AUX        2      4    0    20    1  \n",
       "CCONJ      0      7    0    15    3  \n",
       "DET        2      2    1    39    9  \n",
       "INTJ       0      0    0     4    0  \n",
       "NOUN       1      0    5   402  173  \n",
       "NUM        5      0    2    27   22  \n",
       "PART       1      0    1    36    4  \n",
       "PRON       2     15    0    35    4  \n",
       "PROPN      0      0    2    47   57  \n",
       "PUNCT   3420      0    0     3    0  \n",
       "SCONJ      2    358    1    20    0  \n",
       "SYM        0      0    0     1    0  \n",
       "VERB       1      2    6   923   41  \n",
       "X          0      0    0     5   16  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ---- 10k SUPERVISED INIT (EN) ----\n",
    "tok10k_cs, tag10k_cs = take_first_n_pairs(tokens[\"train\"][\"cs\"], tags[\"train\"][\"cs\"], 10_000)\n",
    "print(\"CS train token pairs used:\", sum(len(s) for s in tok10k_cs))\n",
    "\n",
    "# transitions built from the 10k subset (but still using em_lambdas[\"cs\"])\n",
    "logp_trans_10k_cs, tagset_10k_cs = build_logp_trans_from_train_tags(\"cs\", tag10k_cs)\n",
    "\n",
    "# lexical model built from the 10k subset, lambdas learned on full dev\n",
    "lex_10k_cs = train_lexical_model(tok10k_cs, tag10k_cs,\n",
    "                                 tokens[\"dev\"][\"cs\"], tags[\"dev\"][\"cs\"],\n",
    "                                 unk_threshold=1, add_alpha=0.0)\n",
    "print(\"CS 10k lexical lambdas:\", lex_10k_cs[\"lambdas\"])\n",
    "\n",
    "# decode + evaluate on CS test\n",
    "cs10k_acc, cs10k_cm, _ = decode_and_eval(\"cs\",\n",
    "    tokens[\"test\"][\"cs\"], tags[\"test\"][\"cs\"],\n",
    "    logp_trans_10k_cs, tagset_10k_cs, lex_10k_cs\n",
    ")\n",
    "print(\"10k-init supervised HMM CS test accuracy:\", f\"{cs10k_acc:.4f}\")\n",
    "display(cs10k_cm)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv_nlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
