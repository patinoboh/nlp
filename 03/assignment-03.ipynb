{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa6bf5f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: conllu in /mnt/disk/patrik/nlp/.venv_nlp/lib/python3.10/site-packages (6.0.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install conllu\n",
    "%pip install stanza\n",
    "\n",
    "import conllu\n",
    "import pandas as pd\n",
    "import stanza\n",
    "import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7f38ecd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2026-02-08 16:41:04--  https://raw.githubusercontent.com/UniversalDependencies/UD_Czech-PDTC/refs/heads/master/cs_pdtc-ud-train-la.conllu\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.111.133, 185.199.109.133, 185.199.110.133, ...\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.111.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 24175776 (23M) [text/plain]\n",
      "Saving to: ‘cs_pdtc-ud-train-la.conllu’\n",
      "\n",
      "cs_pdtc-ud-train-la 100%[===================>]  23,06M  38,4MB/s    in 0,6s    \n",
      "\n",
      "2026-02-08 16:41:04 (38,4 MB/s) - ‘cs_pdtc-ud-train-la.conllu’ saved [24175776/24175776]\n",
      "\n",
      "--2026-02-08 16:41:05--  https://raw.githubusercontent.com/UniversalDependencies/UD_Czech-PDTC/refs/heads/master/cs_pdtc-ud-test.conllu\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.111.133, 185.199.108.133, 185.199.109.133, ...\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.111.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 39742361 (38M) [text/plain]\n",
      "Saving to: ‘cs_pdtc-ud-test.conllu’\n",
      "\n",
      "cs_pdtc-ud-test.con 100%[===================>]  37,90M  39,6MB/s    in 1,0s    \n",
      "\n",
      "2026-02-08 16:41:08 (39,6 MB/s) - ‘cs_pdtc-ud-test.conllu’ saved [39742361/39742361]\n",
      "\n",
      "--2026-02-08 16:41:08--  https://raw.githubusercontent.com/UniversalDependencies/UD_Czech-PDTC/refs/heads/master/cs_pdtc-ud-dev.conllu\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.110.133, 185.199.111.133, 185.199.108.133, ...\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.110.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 50117913 (48M) [text/plain]\n",
      "Saving to: ‘cs_pdtc-ud-dev.conllu’\n",
      "\n",
      "cs_pdtc-ud-dev.conl 100%[===================>]  47,80M  39,0MB/s    in 1,2s    \n",
      "\n",
      "2026-02-08 16:41:10 (39,0 MB/s) - ‘cs_pdtc-ud-dev.conllu’ saved [50117913/50117913]\n",
      "\n",
      "--2026-02-08 16:41:10--  https://raw.githubusercontent.com/UniversalDependencies/UD_English-GUM/refs/heads/master/en_gum-ud-train.conllu\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.110.133, 185.199.109.133, 185.199.111.133, ...\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.110.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 18490556 (18M) [text/plain]\n",
      "Saving to: ‘en_gum-ud-train.conllu’\n",
      "\n",
      "en_gum-ud-train.con 100%[===================>]  17,63M  41,7MB/s    in 0,4s    \n",
      "\n",
      "2026-02-08 16:41:11 (41,7 MB/s) - ‘en_gum-ud-train.conllu’ saved [18490556/18490556]\n",
      "\n",
      "--2026-02-08 16:41:12--  https://raw.githubusercontent.com/UniversalDependencies/UD_English-GUM/refs/heads/master/en_gum-ud-test.conllu\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.111.133, 185.199.108.133, 185.199.109.133, ...\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.111.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 2926279 (2,8M) [text/plain]\n",
      "Saving to: ‘en_gum-ud-test.conllu’\n",
      "\n",
      "en_gum-ud-test.conl 100%[===================>]   2,79M  --.-KB/s    in 0,1s    \n",
      "\n",
      "2026-02-08 16:41:12 (27,1 MB/s) - ‘en_gum-ud-test.conllu’ saved [2926279/2926279]\n",
      "\n",
      "--2026-02-08 16:41:12--  https://raw.githubusercontent.com/UniversalDependencies/UD_English-GUM/refs/heads/master/en_gum-ud-dev.conllu\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.110.133, 185.199.111.133, 185.199.109.133, ...\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.110.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 2924380 (2,8M) [text/plain]\n",
      "Saving to: ‘en_gum-ud-dev.conllu’\n",
      "\n",
      "en_gum-ud-dev.conll 100%[===================>]   2,79M  --.-KB/s    in 0,1s    \n",
      "\n",
      "2026-02-08 16:41:12 (27,0 MB/s) - ‘en_gum-ud-dev.conllu’ saved [2924380/2924380]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget https://raw.githubusercontent.com/UniversalDependencies/UD_Czech-PDTC/refs/heads/master/cs_pdtc-ud-train-la.conllu -O cs_pdtc-ud-train-la.conllu\n",
    "!wget https://raw.githubusercontent.com/UniversalDependencies/UD_Czech-PDTC/refs/heads/master/cs_pdtc-ud-test.conllu -O cs_pdtc-ud-test.conllu\n",
    "!wget https://raw.githubusercontent.com/UniversalDependencies/UD_Czech-PDTC/refs/heads/master/cs_pdtc-ud-dev.conllu -O cs_pdtc-ud-dev.conllu\n",
    "\n",
    "!wget https://raw.githubusercontent.com/UniversalDependencies/UD_English-GUM/refs/heads/master/en_gum-ud-train.conllu -O en_gum-ud-train.conllu\n",
    "!wget https://raw.githubusercontent.com/UniversalDependencies/UD_English-GUM/refs/heads/master/en_gum-ud-test.conllu -O en_gum-ud-test.conllu\n",
    "!wget https://raw.githubusercontent.com/UniversalDependencies/UD_English-GUM/refs/heads/master/en_gum-ud-dev.conllu -O en_gum-ud-dev.conllu\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "c8812cc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict, Counter\n",
    "from itertools import pairwise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "bd83b4ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "filenames_test = {\n",
    "    \"cs\" : \"cs_pdtc-ud-test.conllu\",\n",
    "    \"en\": \"en_gum-ud-test.conllu\"\n",
    "}\n",
    "\n",
    "filenames_dev = {\n",
    "    \"cs\" : \"cs_pdtc-ud-dev.conllu\",\n",
    "    \"en\": \"en_gum-ud-dev.conllu\"\n",
    "}\n",
    "\n",
    "filenames_train = {\n",
    "    \"cs\" : \"cs_pdtc-ud-train-la.conllu\",\n",
    "    \"en\": \"en_gum-ud-train.conllu\"\n",
    "}\n",
    "\n",
    "filenames = {\n",
    "    \"test\": filenames_test,\n",
    "    \"dev\": filenames_dev,\n",
    "    \"train\": filenames_train\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "43d8629f",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = dict()\n",
    "\n",
    "for name, d in filenames.items():\n",
    "    corpus[name] = dict()\n",
    "    for lang, filename in d.items():\n",
    "        with open(filename, \"r\") as f:\n",
    "            corpus[name][lang] = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22b0b176",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-02-08 16:41:25 INFO: Checking for updates to resources.json in case models have been updated.  Note: this behavior can be turned off with download_method=None or download_method=DownloadMethod.REUSE_RESOURCES\n",
      "Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/main/resources_1.11.0.json: 436kB [00:00, 21.9MB/s]                    \n",
      "2026-02-08 16:41:25 INFO: Downloaded file to /home/patrik/stanza_resources/resources.json\n",
      "2026-02-08 16:41:26 INFO: Loading these models for language: en (English):\n",
      "===============================\n",
      "| Processor | Package         |\n",
      "-------------------------------\n",
      "| tokenize  | combined        |\n",
      "| pos       | combined_charlm |\n",
      "===============================\n",
      "\n",
      "2026-02-08 16:41:26 INFO: Using device: cpu\n",
      "2026-02-08 16:41:26 INFO: Loading: tokenize\n",
      "2026-02-08 16:41:26 INFO: Loading: pos\n",
      "2026-02-08 16:41:36 INFO: Done loading processors!\n",
      "2026-02-08 16:41:36 INFO: Checking for updates to resources.json in case models have been updated.  Note: this behavior can be turned off with download_method=None or download_method=DownloadMethod.REUSE_RESOURCES\n",
      "Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/main/resources_1.11.0.json: 436kB [00:00, 12.6MB/s]                    \n",
      "2026-02-08 16:41:36 INFO: Downloaded file to /home/patrik/stanza_resources/resources.json\n",
      "2026-02-08 16:41:37 INFO: Loading these models for language: cs (Czech):\n",
      "============================\n",
      "| Processor | Package      |\n",
      "----------------------------\n",
      "| tokenize  | pdt          |\n",
      "| pos       | pdt_nocharlm |\n",
      "============================\n",
      "\n",
      "2026-02-08 16:41:37 INFO: Using device: cpu\n",
      "2026-02-08 16:41:37 INFO: Loading: tokenize\n",
      "2026-02-08 16:41:37 INFO: Loading: pos\n",
      "2026-02-08 16:41:41 INFO: Done loading processors!\n"
     ]
    }
   ],
   "source": [
    "nlp_en = stanza.Pipeline(lang='en', processors='tokenize,pos', tokenize_pretokenized=True)\n",
    "nlp_cs = stanza.Pipeline(lang='cs', processors='tokenize,pos', tokenize_pretokenized=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b094922",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "English train size : 177410\n",
      "Czech dev size : 384431\n",
      "Czech test size : 305808\n"
     ]
    }
   ],
   "source": [
    "# MANUAL FUNCTIONS - FOR DEBUGGING AND STUFF - NOT USED CURRENTLY\n",
    "\n",
    "def line_number_check(data, text):\n",
    "    i=0\n",
    "    for line in data.split(\"\\n\"):\n",
    "        splitted = line.split(\"\\t\")\n",
    "        if len(splitted) == 0 or splitted[0].startswith(\"#\") or \"-\" in splitted[0] or \".\" in splitted[0] or splitted[0] == \"\\n\" or splitted[0] == \"\":\n",
    "            continue\n",
    "        i += 1\n",
    "    print(f\"{text} size : {i}\")\n",
    "\n",
    "\n",
    "def word_tag_count(data, text):\n",
    "    word_tag_pairs = set()\n",
    "    i = 0\n",
    "    for line in data.split(\"\\n\"):\n",
    "        splitted = line.split(\"\\t\")\n",
    "        if len(splitted) == 0 or splitted[0].startswith(\"#\") or \"-\" in splitted[0] or \".\" in splitted[0] or splitted[0] == \"\\n\" or splitted[0] == \"\":\n",
    "            continue\n",
    "        word_tag_pairs.add((splitted[1], splitted[4]))\n",
    "        i+=1\n",
    "\n",
    "    print(f\"{text} size : {i}\")\n",
    "\n",
    "def word_tag_count(data, text):\n",
    "    word_tag_pairs = set()\n",
    "    i = 0\n",
    "    for line in data.split(\"\\n\"):\n",
    "        splitted = line.split(\"\\t\")\n",
    "        if len(splitted) == 0 or splitted[0].startswith(\"#\") or \"-\" in splitted[0] or \".\" in splitted[0] or splitted[0] == \"\\n\" or splitted[0] == \"\":\n",
    "            continue\n",
    "        word_tag_pairs.add((splitted[1], splitted[4]))\n",
    "        i+=1\n",
    "\n",
    "    print(f\"{text} size : {i}\")\n",
    "    # print(f\"{text} word-tag pairs : {len(word_tag_pairs)}\")\n",
    "\n",
    "# line_number_check(corpus[\"train\"][\"en\"], \"English train\")\n",
    "# line_number_check(corpus[\"dev\"][\"cs\"], \"Czech dev\")\n",
    "# line_number_check(corpus[\"test\"][\"cs\"], \"Czech test\")\n",
    "\n",
    "# word_tag_count(corpus[\"test\"][\"en\"], \"English test\")\n",
    "# word_tag_count(\"\\n\\n\".join(corpus[\"test\"][\"cs\"].split(\"\\n\\n\")[:1500]), \"Czech test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31b2028b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BEFORE TRUNCATION TO 1_500 SENTENCES\n",
      "test-cs sentence count: 20187 word/tag pairs (lines): 305808\n",
      "test-en sentence count: 1464 word/tag pairs (lines): 28397\n",
      "dev-cs sentence count: 22666 word/tag pairs (lines): 384431\n",
      "dev-en sentence count: 1575 word/tag pairs (lines): 28119\n",
      "train-cs sentence count: 12519 word/tag pairs (lines): 218409\n",
      "train-en sentence count: 10224 word/tag pairs (lines): 177410\n"
     ]
    }
   ],
   "source": [
    "def tagize(filename, text, max_sentences=999_999_999):\n",
    "    tokens = []\n",
    "    tags = []\n",
    "    sentence_count=0\n",
    "    tag_count = 0\n",
    "    with open (filename, \"r\") as f:\n",
    "        for sentence in conllu.parse_incr(f):\n",
    "            sentence_tokens = []\n",
    "            sentence_tags = []\n",
    "            if sentence_count >= max_sentences:\n",
    "                break\n",
    "            for token in sentence:\n",
    "                if isinstance(token[\"id\"], (list, tuple)) and (\".\" in token[\"id\"] or \"-\" in token[\"id\"]):\n",
    "                    continue\n",
    "                # print(token[\"form\"], token[\"upos\"])\n",
    "                tag_count += 1\n",
    "                sentence_tokens.append(token[\"form\"])\n",
    "                sentence_tags.append(token[\"upos\"])\n",
    "            \n",
    "            sentence_count += 1\n",
    "            tokens.append(sentence_tokens)\n",
    "            tags.append(sentence_tags)\n",
    "    print(text, \"sentence count:\", sentence_count, \"word/tag pairs (lines):\", tag_count)\n",
    "    return tokens, tags\n",
    "\n",
    "\n",
    "print(\"BEFORE TRUNCATION TO 1_500 SENTENCES\")\n",
    "pairs = {type: {lang: tagize(filename, f\"{type}-{lang}\") for lang, filename in d.items()} for type, d in filenames.items()}\n",
    "# a,b = tagize(filenames[\"test\"][\"en\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "f80386d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRUNCATING TEST SETS\n",
      "test-cs sentence count: 1500 word/tag pairs (lines): 22844\n",
      "test-en sentence count: 1464 word/tag pairs (lines): 28397\n"
     ]
    }
   ],
   "source": [
    "print(\"TRUNCATING TEST SETS\")\n",
    "pairs[\"test\"] = {lang: tagize(filename, f\"test-{lang}\", max_sentences=1500) for lang, filename in filenames[\"test\"].items()}\n",
    "tokens = {type: {lang: pair[0] for lang, pair in d.items()} for type, d in pairs.items()}\n",
    "tags = {type: {lang: pair[1] for lang, pair in d.items()} for type, d in pairs.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "f2d70054",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_en = nlp_en(tokens[\"test\"][\"en\"])\n",
    "doc_cs = nlp_cs(tokens[\"test\"][\"cs\"][:1500])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56efcb11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stanza EN test accuracy: 97.8308%\n",
      "Stanza EN confusion matrix below\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>pred</th>\n",
       "      <th>ADJ</th>\n",
       "      <th>ADP</th>\n",
       "      <th>ADV</th>\n",
       "      <th>AUX</th>\n",
       "      <th>CCONJ</th>\n",
       "      <th>DET</th>\n",
       "      <th>INTJ</th>\n",
       "      <th>NOUN</th>\n",
       "      <th>NUM</th>\n",
       "      <th>PART</th>\n",
       "      <th>PRON</th>\n",
       "      <th>PROPN</th>\n",
       "      <th>PUNCT</th>\n",
       "      <th>SCONJ</th>\n",
       "      <th>SYM</th>\n",
       "      <th>VERB</th>\n",
       "      <th>X</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gold</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ADJ</th>\n",
       "      <td>1755</td>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>34</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ADP</th>\n",
       "      <td>0</td>\n",
       "      <td>2833</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ADV</th>\n",
       "      <td>37</td>\n",
       "      <td>36</td>\n",
       "      <td>1226</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AUX</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1520</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CCONJ</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>987</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DET</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2515</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>INTJ</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>155</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NOUN</th>\n",
       "      <td>25</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>4806</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>59</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NUM</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>478</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PART</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>668</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PRON</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2178</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PROPN</th>\n",
       "      <td>40</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1677</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PUNCT</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3547</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SCONJ</th>\n",
       "      <td>0</td>\n",
       "      <td>22</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>438</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SYM</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>VERB</th>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>33</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2951</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>X</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "pred    ADJ   ADP   ADV   AUX  CCONJ   DET  INTJ  NOUN  NUM  PART  PRON  \\\n",
       "gold                                                                      \n",
       "ADJ    1755     2    11     0      0     0     0    34    0     0     0   \n",
       "ADP       0  2833    12     0      2     0     0     0    0     1     0   \n",
       "ADV      37    36  1226     0      0    14     6     8    0     0     3   \n",
       "AUX       0     0     0  1520      0     0     0     0    0     0     0   \n",
       "CCONJ     0     0     0     0    987     0     0     0    0     0     0   \n",
       "DET       0     0     1     0      3  2515     1     0    0     0     1   \n",
       "INTJ      1     4    12     0      1     0   155     2    0     0     0   \n",
       "NOUN     25     0     0     1      0     0     2  4806    3     0     1   \n",
       "NUM       0     1     0     0      0     0     0     0  478     0     0   \n",
       "PART      0     1     0     1      0     1     0     0    0   668     0   \n",
       "PRON      0     0     0     0      0     2     0     1    0     0  2178   \n",
       "PROPN    40     1     0     0      0     1     1    64    2     0     0   \n",
       "PUNCT     0     0     0     0      0     0     0     0    0     2     0   \n",
       "SCONJ     0    22     1     0      0     0     0     0    0     0     7   \n",
       "SYM       0     0     0     0      0     0     0     5    0     0     0   \n",
       "VERB     23     0     0    12      0     0     1    33    0     0     0   \n",
       "X         0     0     0     0      0     0     0     3    4     0     0   \n",
       "\n",
       "pred   PROPN  PUNCT  SCONJ  SYM  VERB   X  \n",
       "gold                                       \n",
       "ADJ       13      0      0    0    18   0  \n",
       "ADP        2      0     15    0     0   0  \n",
       "ADV        1      0      4    0     1   0  \n",
       "AUX        0      0      0    0    13   0  \n",
       "CCONJ      0      0      1    0     0   0  \n",
       "DET        0      0      0    0     0   0  \n",
       "INTJ       1      0      3    0     2   3  \n",
       "NOUN      59      0      0    0     8   1  \n",
       "NUM        0      0      0    0     0   0  \n",
       "PART       0      0      0    0     0   0  \n",
       "PRON       0      0      6    0     0   0  \n",
       "PROPN   1677      0      0    0     1   0  \n",
       "PUNCT      0   3547      0    1     0   0  \n",
       "SCONJ      0      0    438    0     0   0  \n",
       "SYM        0      2      0   29     0   0  \n",
       "VERB       0      0      0    0  2951   0  \n",
       "X          8      0      0    0     0  18  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stanza CS test accuracy: 97.2903%\n",
      "Stanza CS confusion matrix below\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>pred</th>\n",
       "      <th>ADJ</th>\n",
       "      <th>ADP</th>\n",
       "      <th>ADV</th>\n",
       "      <th>AUX</th>\n",
       "      <th>CCONJ</th>\n",
       "      <th>DET</th>\n",
       "      <th>INTJ</th>\n",
       "      <th>NOUN</th>\n",
       "      <th>NUM</th>\n",
       "      <th>PART</th>\n",
       "      <th>PRON</th>\n",
       "      <th>PROPN</th>\n",
       "      <th>PUNCT</th>\n",
       "      <th>SCONJ</th>\n",
       "      <th>SYM</th>\n",
       "      <th>VERB</th>\n",
       "      <th>X</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gold</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ADJ</th>\n",
       "      <td>2572</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ADP</th>\n",
       "      <td>0</td>\n",
       "      <td>2109</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ADV</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>878</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AUX</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>774</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CCONJ</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>731</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DET</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>916</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>INTJ</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NOUN</th>\n",
       "      <td>12</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>5525</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>32</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NUM</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>616</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PART</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>230</td>\n",
       "      <td>0</td>\n",
       "      <td>79</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>160</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PRON</th>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>730</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PROPN</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>36</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1026</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PUNCT</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3461</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SCONJ</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>438</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SYM</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>38</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>VERB</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2148</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>X</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>89</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "pred    ADJ   ADP  ADV  AUX  CCONJ  DET  INTJ  NOUN  NUM  PART  PRON  PROPN  \\\n",
       "gold                                                                          \n",
       "ADJ    2572     0    1    0      0    0     0    16    1     0     0     11   \n",
       "ADP       0  2109    0    0      0    0     0     3    0     0     1      0   \n",
       "ADV       1     2  878    0     16    1     0    10    0     5     3      0   \n",
       "AUX       0     0    0  774      0    0     0     0    0     0     0      0   \n",
       "CCONJ     0     0   12    0    731    0     0     0    0     2     0      0   \n",
       "DET       1     0    1    0      0  916     0     0    0     0     0      0   \n",
       "INTJ      0     0    0    0      0    0    14     2    0     3     0      1   \n",
       "NOUN     12     3    7    0      4    0     4  5525    0     0     0     32   \n",
       "NUM       0     0    0    0      0    0     0     0  616     0     0      0   \n",
       "PART      0     0  230    0     79    0     2     2    0   160     0      0   \n",
       "PRON      1     6    0    4      0   14     0     4    0     0   730      0   \n",
       "PROPN     2     0    0    0      0    0     3    36    0     0     3   1026   \n",
       "PUNCT     0     0    0    0      0    0     0     0    0     0     0      0   \n",
       "SCONJ     0     0    7    0      0    0     0     0    0     2     3      0   \n",
       "SYM       0     0    0    0      0    0     0     3    0     0     0      0   \n",
       "VERB      1     0    0    0      0    0     0     4    0     0     0      4   \n",
       "X         0     0    0    0      0    0     0     3    0     0     0     17   \n",
       "\n",
       "pred   PUNCT  SCONJ  SYM  VERB   X  \n",
       "gold                                \n",
       "ADJ        0      0    0     0   1  \n",
       "ADP        0      0    0     1   0  \n",
       "ADV        0      0    0     1   0  \n",
       "AUX        0      0    0     2   0  \n",
       "CCONJ      0     11    0     0   0  \n",
       "DET        0      0    0     1   0  \n",
       "INTJ       0      0    0     0   0  \n",
       "NOUN       0      0    6     3   4  \n",
       "NUM        0      0    0     0   0  \n",
       "PART       0      2    0     0   0  \n",
       "PRON       0      0    0     0   0  \n",
       "PROPN      0      0    0     1   1  \n",
       "PUNCT   3461      0    0     0   0  \n",
       "SCONJ      0    438    0     0   0  \n",
       "SYM        0      0   38     0   0  \n",
       "VERB       0      0    0  2148   0  \n",
       "X          0      0    0     0  89  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def stanza_eval(doc, tokens_sents, gold_sents):\n",
    "    \"\"\"tokens_sents: List[List[str]], gold_sents: List[List[str]] (UPOS)\"\"\"\n",
    "    pred_sents = [[w.upos for w in s.words] for s in doc.sentences]\n",
    "\n",
    "    # accuracy\n",
    "    correct = total = 0\n",
    "    for g, p in zip(gold_sents, pred_sents):\n",
    "        if len(g) != len(p):\n",
    "            raise ValueError(f\"Length mismatch in a sentence: gold={len(g)} pred={len(p)} \"\n",
    "                             \"(check MWT/ellipsis filtering + tokenize_pretokenized=True)\")\n",
    "        for gt, pt in zip(g, p):\n",
    "            total += 1\n",
    "            correct += (gt == pt)\n",
    "    acc = 100.0 * correct / total\n",
    "\n",
    "    # confusion matrix (rows=gold, cols=pred)\n",
    "    gflat = [t for sent in gold_sents for t in sent]\n",
    "    pflat = [t for sent in pred_sents for t in sent]\n",
    "    cm = pd.crosstab(pd.Series(gflat, name=\"gold\"), pd.Series(pflat, name=\"pred\"))\n",
    "    return acc, cm\n",
    "\n",
    "en_acc, en_cm = stanza_eval(doc_en, tokens[\"test\"][\"en\"], tags[\"test\"][\"en\"])\n",
    "print(f\"Stanza EN test accuracy: {en_acc:.4f}%\")\n",
    "print(\"Stanza EN confusion matrix below\")\n",
    "display(en_cm)\n",
    "\n",
    "cs_acc, cs_cm = stanza_eval(doc_cs, tokens[\"test\"][\"cs\"][:1500], tags[\"test\"][\"cs\"][:1500])\n",
    "print(f\"Stanza CS test accuracy: {cs_acc:.4f}%\")\n",
    "print(\"Stanza CS confusion matrix below\")\n",
    "display(cs_cm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "36100994",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRUNKATING CS DEV SET\n",
      "dev-cs sentence count: 1500 word/tag pairs (lines): 21752\n"
     ]
    }
   ],
   "source": [
    "print(\"TRUNKATING CS DEV SET\")\n",
    "tokens[\"dev\"][\"cs\"], tags[\"dev\"][\"cs\"] = tagize(filenames[\"dev\"][\"cs\"], \"dev-cs\", max_sentences=1500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "708c4c32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sizes check\n",
      "test-cs tokenized sentences: 1500 tokens : 22844\n",
      "test-en tokenized sentences: 1464 tokens : 28397\n",
      "dev-cs tokenized sentences: 1500 tokens : 21752\n",
      "dev-en tokenized sentences: 1500 tokens : 26930\n",
      "train-cs tokenized sentences: 12519 tokens : 218409\n",
      "train-en tokenized sentences: 10224 tokens : 177410\n"
     ]
    }
   ],
   "source": [
    "# Check sizes\n",
    "print(\"Sizes check\")\n",
    "for type, d in tokens.items():\n",
    "    for lang, sents in d.items():\n",
    "        print(f\"{type}-{lang} tokenized sentences: {len(sents)} tokens : {sum(len(s) for s in sents)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "8be7afeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_special_symbol = \"<s>\"\n",
    "end_special_symbol = \"</s>\"\n",
    "\n",
    "get_unigrams = lambda tokens : Counter(tokens)\n",
    "get_bigrams = lambda tokens : Counter(zip([start_special_symbol] + tokens, tokens + [end_special_symbol]))\n",
    "get_trigrams = lambda tokens : Counter(zip(2 * [start_special_symbol] + tokens, [start_special_symbol] + tokens + [end_special_symbol], tokens + 2 * [end_special_symbol]))\n",
    "\n",
    "def get_all_ngrams(tokens_or_tags, n=1):\n",
    "    ngrams = {\n",
    "        1: get_unigrams,\n",
    "        2: get_bigrams,\n",
    "        3: get_trigrams\n",
    "    }[n]\n",
    "    all = Counter()    \n",
    "    for sentence in tokens_or_tags:\n",
    "        all.update(ngrams(sentence))\n",
    "    return all\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83841794",
   "metadata": {},
   "outputs": [],
   "source": [
    "ngrams_train = {i: {lang: get_all_ngrams(tokens[\"train\"][lang], n=i) for lang in tokens[\"train\"]} for i in range(1, 4)}\n",
    "ngrams_dev = {i: {lang: get_all_ngrams(tokens[\"dev\"][lang], n=i) for lang in tokens[\"dev\"]} for i in range(1, 4)}\n",
    "ngrams_test = {i: {lang: get_all_ngrams(tokens[\"test\"][lang], n=i) for lang in tokens[\"test\"]} for i in range(1, 4)}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv_nlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
